// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: v1/video/video.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

/// sensory.api.video

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Specifies how sensitive the recognition threshold of the model should be
public enum Sensory_Api_V1_Video_RecognitionThreshold: SwiftProtobuf.Enum {
  public typealias RawValue = Int
  case low // = 0
  case medium // = 1
  case high // = 2
  case highest // = 3
  case UNRECOGNIZED(Int)

  public init() {
    self = .low
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .low
    case 1: self = .medium
    case 2: self = .high
    case 3: self = .highest
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .low: return 0
    case .medium: return 1
    case .high: return 2
    case .highest: return 3
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Sensory_Api_V1_Video_RecognitionThreshold: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Sensory_Api_V1_Video_RecognitionThreshold] = [
    .low,
    .medium,
    .high,
    .highest,
  ]
}

#endif  // swift(>=4.2)

/// A model that is available for use
public struct Sensory_Api_V1_Video_VideoModel {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The name of the model
  public var name: String = String()

  /// Boolean representing if a model can be used in enrollment
  public var isEnrollable: Bool = false

  /// Model type string
  public var modelType: Sensory_Api_Common_ModelType = .voiceBiometricTextDependent

  /// Specific object for which this model is made
  public var fixedObject: String = String()

  /// List of versions available for this model
  public var versions: [String] = []

  /// The technology backing this model
  public var technology: Sensory_Api_Common_TechnologyType = .notSet

  /// Indicates if liveness is supported by this model
  public var isLivenessSupported: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request to get a list of the available models
public struct Sensory_Api_V1_Video_GetModelsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response containing the models currently available
public struct Sensory_Api_V1_Video_GetModelsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// List of supported models
  public var models: [Sensory_Api_V1_Video_VideoModel] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// The top-level message sent by the client for the `CreateEnrollment` method.
/// Multiple `CreateEnrollmentRequest` messages are sent in a stream. The first message
/// must contain a `config` message and must not contain `imageContent`.
/// All subsequent messages must contain `imageContent` and
/// must not contain a `config` message.
public struct Sensory_Api_V1_Video_CreateEnrollmentRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The streaming request, which is either a config or image content.
  public var streamingRequest: Sensory_Api_V1_Video_CreateEnrollmentRequest.OneOf_StreamingRequest? = nil

  /// Provides information that specifies how to process the
  /// request. The first `CreateEnrollmentRequest` message must contain a
  /// `config`  message.
  public var config: Sensory_Api_V1_Video_CreateEnrollmentConfig {
    get {
      if case .config(let v)? = streamingRequest {return v}
      return Sensory_Api_V1_Video_CreateEnrollmentConfig()
    }
    set {streamingRequest = .config(newValue)}
  }

  /// The image content to be recognized sent as bytes.
  public var imageContent: Data {
    get {
      if case .imageContent(let v)? = streamingRequest {return v}
      return Data()
    }
    set {streamingRequest = .imageContent(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The streaming request, which is either a config or image content.
  public enum OneOf_StreamingRequest: Equatable {
    /// Provides information that specifies how to process the
    /// request. The first `CreateEnrollmentRequest` message must contain a
    /// `config`  message.
    case config(Sensory_Api_V1_Video_CreateEnrollmentConfig)
    /// The image content to be recognized sent as bytes.
    case imageContent(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Video_CreateEnrollmentRequest.OneOf_StreamingRequest, rhs: Sensory_Api_V1_Video_CreateEnrollmentRequest.OneOf_StreamingRequest) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.config, .config): return {
        guard case .config(let l) = lhs, case .config(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.imageContent, .imageContent): return {
        guard case .imageContent(let l) = lhs, case .imageContent(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// The top-level message sent by the client for the `Authenticate` method.
/// Multiple `AuthenticateRequest` messages are sent in a stream. The first message
/// must contain a `config` message and must not contain `imageContent`.
/// All subsequent messages must contain `imageContent` and
/// must not contain a `config` message.
public struct Sensory_Api_V1_Video_AuthenticateRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The streaming request, which is either a config or image content.
  public var streamingRequest: Sensory_Api_V1_Video_AuthenticateRequest.OneOf_StreamingRequest? = nil

  /// Provides information that specifies how to process the
  /// request. The first `AuthenticateRequest` message must contain a
  /// `config`  message.
  public var config: Sensory_Api_V1_Video_AuthenticateConfig {
    get {
      if case .config(let v)? = streamingRequest {return v}
      return Sensory_Api_V1_Video_AuthenticateConfig()
    }
    set {streamingRequest = .config(newValue)}
  }

  /// The image content to be recognized sent as bytes.
  public var imageContent: Data {
    get {
      if case .imageContent(let v)? = streamingRequest {return v}
      return Data()
    }
    set {streamingRequest = .imageContent(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The streaming request, which is either a config or image content.
  public enum OneOf_StreamingRequest: Equatable {
    /// Provides information that specifies how to process the
    /// request. The first `AuthenticateRequest` message must contain a
    /// `config`  message.
    case config(Sensory_Api_V1_Video_AuthenticateConfig)
    /// The image content to be recognized sent as bytes.
    case imageContent(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Video_AuthenticateRequest.OneOf_StreamingRequest, rhs: Sensory_Api_V1_Video_AuthenticateRequest.OneOf_StreamingRequest) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.config, .config): return {
        guard case .config(let l) = lhs, case .config(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.imageContent, .imageContent): return {
        guard case .imageContent(let l) = lhs, case .imageContent(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// The top-level message sent by the client for the `ValidateLiveness` method.
/// Multiple `ValidateRecognitionRequest` messages are sent in a stream. The first message
/// must contain a `config` message and must not contain `imageContent`.
/// All subsequent messages must contain `imageContent` and
/// must not contain a `config` message.
public struct Sensory_Api_V1_Video_ValidateRecognitionRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The streaming request, which is either a config or image content.
  public var streamingRequest: Sensory_Api_V1_Video_ValidateRecognitionRequest.OneOf_StreamingRequest? = nil

  /// Provides information that specifies how to process the
  /// request. The first `ValidateRecognitionRequest` message must contain a
  /// `config`  message.
  public var config: Sensory_Api_V1_Video_ValidateRecognitionConfig {
    get {
      if case .config(let v)? = streamingRequest {return v}
      return Sensory_Api_V1_Video_ValidateRecognitionConfig()
    }
    set {streamingRequest = .config(newValue)}
  }

  /// The image content to be recognized sent as bytes.
  public var imageContent: Data {
    get {
      if case .imageContent(let v)? = streamingRequest {return v}
      return Data()
    }
    set {streamingRequest = .imageContent(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The streaming request, which is either a config or image content.
  public enum OneOf_StreamingRequest: Equatable {
    /// Provides information that specifies how to process the
    /// request. The first `ValidateRecognitionRequest` message must contain a
    /// `config`  message.
    case config(Sensory_Api_V1_Video_ValidateRecognitionConfig)
    /// The image content to be recognized sent as bytes.
    case imageContent(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Video_ValidateRecognitionRequest.OneOf_StreamingRequest, rhs: Sensory_Api_V1_Video_ValidateRecognitionRequest.OneOf_StreamingRequest) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.config, .config): return {
        guard case .config(let l) = lhs, case .config(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.imageContent, .imageContent): return {
        guard case .imageContent(let l) = lhs, case .imageContent(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// Response to an enrollment request
public struct Sensory_Api_V1_Video_CreateEnrollmentResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Percent Complete as values between 0 and 100
  public var percentComplete: Int64 = 0

  /// Liveness check bit. This value with always be false if 'isLivenessEnabled' is set to false in the CreateEnrollmentConfig
  public var isAlive: Bool = false

  /// If enrollment is successful, this value will be the unique Enrollment ID
  public var enrollmentID: String = String()

  /// Model used for enrollment
  public var modelName: String = String()

  /// Model version used for enrollment
  public var modelVersion: String = String()

  /// Score of the enrollment. Currently only used for error messages.
  public var score: Float = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response to an authentication request
public struct Sensory_Api_V1_Video_AuthenticateResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Success / Failure bit
  public var success: Bool = false

  /// Score of the authentication (lower is better)
  public var score: Float = 0

  /// Liveness check bit. This value with always be false if 'isLivenessEnabled' is set to false in the AuthenticateConfig
  public var isAlive: Bool = false

  /// Optional token that will be returned upon a successful authentication if doIncludeToken is set to true in the AuthenticateConfig
  public var token: Sensory_Api_Common_TokenResponse {
    get {return _token ?? Sensory_Api_Common_TokenResponse()}
    set {_token = newValue}
  }
  /// Returns true if `token` has been explicitly set.
  public var hasToken: Bool {return self._token != nil}
  /// Clears the value of `token`. Subsequent reads from it will return its default value.
  public mutating func clearToken() {self._token = nil}

  /// The userID of the authenticated user
  /// Useful when evaluating enrollment groups
  public var userID: String = String()

  /// The enrollment ID of the authenticated enrollment
  /// Useful when evaluating enrollment groups
  public var enrollmentID: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _token: Sensory_Api_Common_TokenResponse? = nil
}

/// Response to a liveness recognition request
public struct Sensory_Api_V1_Video_LivenessRecognitionResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Success / Failure bit
  public var isAlive: Bool = false

  /// Score of the liveness (lower is better)
  public var score: Float = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Provides information for an enrollment
public struct Sensory_Api_V1_Video_CreateEnrollmentConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The unique user Identifer. This value should be a unique email address or username known by the user.
  public var userID: String = String()

  /// The unique device Identifer. This value should be something retrieved by the devie prior to enrollment (like MAC Address)
  /// this value is used to identify a device uniquely across multiple enrollments
  public var deviceID: String = String()

  /// Name of background model to be enrolled in
  /// Background models can be retrieved from the GetModels() gRPC call
  public var modelName: String = String()

  /// Description of the enrollment as entered by the user.
  /// Max length is 1023 characters
  public var description_p: String = String()

  /// Enable a liveness check on the image, which will further improve the security of enrollment at the expense of a slightly slower response.
  public var isLivenessEnabled: Bool = false

  /// The liveness threshold
  public var livenessThreshold: Sensory_Api_V1_Video_RecognitionThreshold = .low

  /// Information about how the video data will be compressed.
  public var compression: Sensory_Api_Common_CompressionConfiguration {
    get {return _compression ?? Sensory_Api_Common_CompressionConfiguration()}
    set {_compression = newValue}
  }
  /// Returns true if `compression` has been explicitly set.
  public var hasCompression: Bool {return self._compression != nil}
  /// Clears the value of `compression`. Subsequent reads from it will return its default value.
  public mutating func clearCompression() {self._compression = nil}

  /// Reference Id allows clients to assign their own identifier to enrollments for various purposes
  /// such as tying an audio and video enrollment together.
  public var referenceID: String = String()

  /// If isLivenessEnabled is true, this determines how many frames need to pass the liveness check before the enrollment can be successful
  /// A value of 0 means that all enrollment frames must pass the liveness check.
  public var numLivenessFramesRequired: Int32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _compression: Sensory_Api_Common_CompressionConfiguration? = nil
}

/// Provides information for an image-based authentication
public struct Sensory_Api_V1_Video_AuthenticateConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// An identifier for what to authenticate against, either an individual enrollment or a group of enrollments
  public var authID: Sensory_Api_V1_Video_AuthenticateConfig.OneOf_AuthID? = nil

  /// Unique identifier created at enrollment
  public var enrollmentID: String {
    get {
      if case .enrollmentID(let v)? = authID {return v}
      return String()
    }
    set {authID = .enrollmentID(newValue)}
  }

  /// Unique identifier for an enrollment group
  public var enrollmentGroupID: String {
    get {
      if case .enrollmentGroupID(let v)? = authID {return v}
      return String()
    }
    set {authID = .enrollmentGroupID(newValue)}
  }

  /// Enable a liveness check on the image, which will further improve the security of authentication at the expense of a slightly slower response.
  public var isLivenessEnabled: Bool = false

  /// The liveness threshold
  public var livenessThreshold: Sensory_Api_V1_Video_RecognitionThreshold = .low

  /// Information aobut how the video data will be compressed.
  public var compression: Sensory_Api_Common_CompressionConfiguration {
    get {return _compression ?? Sensory_Api_Common_CompressionConfiguration()}
    set {_compression = newValue}
  }
  /// Returns true if `compression` has been explicitly set.
  public var hasCompression: Bool {return self._compression != nil}
  /// Clears the value of `compression`. Subsequent reads from it will return its default value.
  public mutating func clearCompression() {self._compression = nil}

  /// A boolean indicating if the response should include an OAuth token for the user associated with the enrollmentId
  /// The OAuth token will only be returned if the authentication is successful.
  /// It's important to note there will be a minor performance hit to authentication, as OAuth token generation is a semi-expensive operation.
  public var doIncludeToken: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// An identifier for what to authenticate against, either an individual enrollment or a group of enrollments
  public enum OneOf_AuthID: Equatable {
    /// Unique identifier created at enrollment
    case enrollmentID(String)
    /// Unique identifier for an enrollment group
    case enrollmentGroupID(String)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Video_AuthenticateConfig.OneOf_AuthID, rhs: Sensory_Api_V1_Video_AuthenticateConfig.OneOf_AuthID) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.enrollmentID, .enrollmentID): return {
        guard case .enrollmentID(let l) = lhs, case .enrollmentID(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.enrollmentGroupID, .enrollmentGroupID): return {
        guard case .enrollmentGroupID(let l) = lhs, case .enrollmentGroupID(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _compression: Sensory_Api_Common_CompressionConfiguration? = nil
}

/// Provides information for a video-based event recognition
public struct Sensory_Api_V1_Video_ValidateRecognitionConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Name of model to validate against
  /// Models can be retrieved from the GetModels() gRPC call
  public var modelName: String = String()

  /// The unique user Identifer
  public var userID: String = String()

  /// The model threshold
  public var threshold: Sensory_Api_V1_Video_RecognitionThreshold = .low

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "sensory.api.v1.video"

extension Sensory_Api_V1_Video_RecognitionThreshold: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "LOW"),
    1: .same(proto: "MEDIUM"),
    2: .same(proto: "HIGH"),
    3: .same(proto: "HIGHEST"),
  ]
}

extension Sensory_Api_V1_Video_VideoModel: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".VideoModel"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .same(proto: "isEnrollable"),
    3: .same(proto: "modelType"),
    4: .same(proto: "fixedObject"),
    5: .same(proto: "versions"),
    6: .same(proto: "technology"),
    7: .same(proto: "isLivenessSupported"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.isEnrollable) }()
      case 3: try { try decoder.decodeSingularEnumField(value: &self.modelType) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.fixedObject) }()
      case 5: try { try decoder.decodeRepeatedStringField(value: &self.versions) }()
      case 6: try { try decoder.decodeSingularEnumField(value: &self.technology) }()
      case 7: try { try decoder.decodeSingularBoolField(value: &self.isLivenessSupported) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if self.isEnrollable != false {
      try visitor.visitSingularBoolField(value: self.isEnrollable, fieldNumber: 2)
    }
    if self.modelType != .voiceBiometricTextDependent {
      try visitor.visitSingularEnumField(value: self.modelType, fieldNumber: 3)
    }
    if !self.fixedObject.isEmpty {
      try visitor.visitSingularStringField(value: self.fixedObject, fieldNumber: 4)
    }
    if !self.versions.isEmpty {
      try visitor.visitRepeatedStringField(value: self.versions, fieldNumber: 5)
    }
    if self.technology != .notSet {
      try visitor.visitSingularEnumField(value: self.technology, fieldNumber: 6)
    }
    if self.isLivenessSupported != false {
      try visitor.visitSingularBoolField(value: self.isLivenessSupported, fieldNumber: 7)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Video_VideoModel, rhs: Sensory_Api_V1_Video_VideoModel) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.isEnrollable != rhs.isEnrollable {return false}
    if lhs.modelType != rhs.modelType {return false}
    if lhs.fixedObject != rhs.fixedObject {return false}
    if lhs.versions != rhs.versions {return false}
    if lhs.technology != rhs.technology {return false}
    if lhs.isLivenessSupported != rhs.isLivenessSupported {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Video_GetModelsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GetModelsRequest"
  public static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let _ = try decoder.nextFieldNumber() {
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Video_GetModelsRequest, rhs: Sensory_Api_V1_Video_GetModelsRequest) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Video_GetModelsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GetModelsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "models"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.models) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.models.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.models, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Video_GetModelsResponse, rhs: Sensory_Api_V1_Video_GetModelsResponse) -> Bool {
    if lhs.models != rhs.models {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Video_CreateEnrollmentRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateEnrollmentRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .same(proto: "imageContent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Sensory_Api_V1_Video_CreateEnrollmentConfig?
        var hadOneofValue = false
        if let current = self.streamingRequest {
          hadOneofValue = true
          if case .config(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .config(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingRequest != nil {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .imageContent(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.streamingRequest {
    case .config?: try {
      guard case .config(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .imageContent?: try {
      guard case .imageContent(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Video_CreateEnrollmentRequest, rhs: Sensory_Api_V1_Video_CreateEnrollmentRequest) -> Bool {
    if lhs.streamingRequest != rhs.streamingRequest {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Video_AuthenticateRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AuthenticateRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .same(proto: "imageContent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Sensory_Api_V1_Video_AuthenticateConfig?
        var hadOneofValue = false
        if let current = self.streamingRequest {
          hadOneofValue = true
          if case .config(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .config(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingRequest != nil {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .imageContent(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.streamingRequest {
    case .config?: try {
      guard case .config(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .imageContent?: try {
      guard case .imageContent(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Video_AuthenticateRequest, rhs: Sensory_Api_V1_Video_AuthenticateRequest) -> Bool {
    if lhs.streamingRequest != rhs.streamingRequest {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Video_ValidateRecognitionRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ValidateRecognitionRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .same(proto: "imageContent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Sensory_Api_V1_Video_ValidateRecognitionConfig?
        var hadOneofValue = false
        if let current = self.streamingRequest {
          hadOneofValue = true
          if case .config(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .config(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingRequest != nil {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .imageContent(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.streamingRequest {
    case .config?: try {
      guard case .config(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .imageContent?: try {
      guard case .imageContent(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Video_ValidateRecognitionRequest, rhs: Sensory_Api_V1_Video_ValidateRecognitionRequest) -> Bool {
    if lhs.streamingRequest != rhs.streamingRequest {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Video_CreateEnrollmentResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateEnrollmentResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "percentComplete"),
    2: .same(proto: "isAlive"),
    3: .same(proto: "enrollmentId"),
    4: .same(proto: "modelName"),
    5: .same(proto: "modelVersion"),
    6: .same(proto: "score"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.percentComplete) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.isAlive) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.enrollmentID) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.modelName) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.modelVersion) }()
      case 6: try { try decoder.decodeSingularFloatField(value: &self.score) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.percentComplete != 0 {
      try visitor.visitSingularInt64Field(value: self.percentComplete, fieldNumber: 1)
    }
    if self.isAlive != false {
      try visitor.visitSingularBoolField(value: self.isAlive, fieldNumber: 2)
    }
    if !self.enrollmentID.isEmpty {
      try visitor.visitSingularStringField(value: self.enrollmentID, fieldNumber: 3)
    }
    if !self.modelName.isEmpty {
      try visitor.visitSingularStringField(value: self.modelName, fieldNumber: 4)
    }
    if !self.modelVersion.isEmpty {
      try visitor.visitSingularStringField(value: self.modelVersion, fieldNumber: 5)
    }
    if self.score != 0 {
      try visitor.visitSingularFloatField(value: self.score, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Video_CreateEnrollmentResponse, rhs: Sensory_Api_V1_Video_CreateEnrollmentResponse) -> Bool {
    if lhs.percentComplete != rhs.percentComplete {return false}
    if lhs.isAlive != rhs.isAlive {return false}
    if lhs.enrollmentID != rhs.enrollmentID {return false}
    if lhs.modelName != rhs.modelName {return false}
    if lhs.modelVersion != rhs.modelVersion {return false}
    if lhs.score != rhs.score {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Video_AuthenticateResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AuthenticateResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "success"),
    2: .same(proto: "score"),
    3: .same(proto: "isAlive"),
    4: .same(proto: "token"),
    5: .same(proto: "userId"),
    6: .same(proto: "enrollmentId"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBoolField(value: &self.success) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.score) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.isAlive) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._token) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.userID) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.enrollmentID) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.success != false {
      try visitor.visitSingularBoolField(value: self.success, fieldNumber: 1)
    }
    if self.score != 0 {
      try visitor.visitSingularFloatField(value: self.score, fieldNumber: 2)
    }
    if self.isAlive != false {
      try visitor.visitSingularBoolField(value: self.isAlive, fieldNumber: 3)
    }
    if let v = self._token {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }
    if !self.userID.isEmpty {
      try visitor.visitSingularStringField(value: self.userID, fieldNumber: 5)
    }
    if !self.enrollmentID.isEmpty {
      try visitor.visitSingularStringField(value: self.enrollmentID, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Video_AuthenticateResponse, rhs: Sensory_Api_V1_Video_AuthenticateResponse) -> Bool {
    if lhs.success != rhs.success {return false}
    if lhs.score != rhs.score {return false}
    if lhs.isAlive != rhs.isAlive {return false}
    if lhs._token != rhs._token {return false}
    if lhs.userID != rhs.userID {return false}
    if lhs.enrollmentID != rhs.enrollmentID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Video_LivenessRecognitionResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".LivenessRecognitionResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "isAlive"),
    2: .same(proto: "score"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBoolField(value: &self.isAlive) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.score) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.isAlive != false {
      try visitor.visitSingularBoolField(value: self.isAlive, fieldNumber: 1)
    }
    if self.score != 0 {
      try visitor.visitSingularFloatField(value: self.score, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Video_LivenessRecognitionResponse, rhs: Sensory_Api_V1_Video_LivenessRecognitionResponse) -> Bool {
    if lhs.isAlive != rhs.isAlive {return false}
    if lhs.score != rhs.score {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Video_CreateEnrollmentConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateEnrollmentConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "userId"),
    2: .same(proto: "deviceId"),
    3: .same(proto: "modelName"),
    4: .same(proto: "description"),
    5: .same(proto: "isLivenessEnabled"),
    6: .same(proto: "livenessThreshold"),
    7: .same(proto: "compression"),
    8: .same(proto: "referenceId"),
    9: .same(proto: "numLivenessFramesRequired"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.userID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.deviceID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.modelName) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.description_p) }()
      case 5: try { try decoder.decodeSingularBoolField(value: &self.isLivenessEnabled) }()
      case 6: try { try decoder.decodeSingularEnumField(value: &self.livenessThreshold) }()
      case 7: try { try decoder.decodeSingularMessageField(value: &self._compression) }()
      case 8: try { try decoder.decodeSingularStringField(value: &self.referenceID) }()
      case 9: try { try decoder.decodeSingularInt32Field(value: &self.numLivenessFramesRequired) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.userID.isEmpty {
      try visitor.visitSingularStringField(value: self.userID, fieldNumber: 1)
    }
    if !self.deviceID.isEmpty {
      try visitor.visitSingularStringField(value: self.deviceID, fieldNumber: 2)
    }
    if !self.modelName.isEmpty {
      try visitor.visitSingularStringField(value: self.modelName, fieldNumber: 3)
    }
    if !self.description_p.isEmpty {
      try visitor.visitSingularStringField(value: self.description_p, fieldNumber: 4)
    }
    if self.isLivenessEnabled != false {
      try visitor.visitSingularBoolField(value: self.isLivenessEnabled, fieldNumber: 5)
    }
    if self.livenessThreshold != .low {
      try visitor.visitSingularEnumField(value: self.livenessThreshold, fieldNumber: 6)
    }
    if let v = self._compression {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    }
    if !self.referenceID.isEmpty {
      try visitor.visitSingularStringField(value: self.referenceID, fieldNumber: 8)
    }
    if self.numLivenessFramesRequired != 0 {
      try visitor.visitSingularInt32Field(value: self.numLivenessFramesRequired, fieldNumber: 9)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Video_CreateEnrollmentConfig, rhs: Sensory_Api_V1_Video_CreateEnrollmentConfig) -> Bool {
    if lhs.userID != rhs.userID {return false}
    if lhs.deviceID != rhs.deviceID {return false}
    if lhs.modelName != rhs.modelName {return false}
    if lhs.description_p != rhs.description_p {return false}
    if lhs.isLivenessEnabled != rhs.isLivenessEnabled {return false}
    if lhs.livenessThreshold != rhs.livenessThreshold {return false}
    if lhs._compression != rhs._compression {return false}
    if lhs.referenceID != rhs.referenceID {return false}
    if lhs.numLivenessFramesRequired != rhs.numLivenessFramesRequired {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Video_AuthenticateConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AuthenticateConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "enrollmentId"),
    2: .same(proto: "enrollmentGroupId"),
    3: .same(proto: "isLivenessEnabled"),
    4: .same(proto: "livenessThreshold"),
    5: .same(proto: "compression"),
    6: .same(proto: "doIncludeToken"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.authID != nil {try decoder.handleConflictingOneOf()}
          self.authID = .enrollmentID(v)
        }
      }()
      case 2: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.authID != nil {try decoder.handleConflictingOneOf()}
          self.authID = .enrollmentGroupID(v)
        }
      }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.isLivenessEnabled) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.livenessThreshold) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._compression) }()
      case 6: try { try decoder.decodeSingularBoolField(value: &self.doIncludeToken) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.authID {
    case .enrollmentID?: try {
      guard case .enrollmentID(let v)? = self.authID else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 1)
    }()
    case .enrollmentGroupID?: try {
      guard case .enrollmentGroupID(let v)? = self.authID else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    if self.isLivenessEnabled != false {
      try visitor.visitSingularBoolField(value: self.isLivenessEnabled, fieldNumber: 3)
    }
    if self.livenessThreshold != .low {
      try visitor.visitSingularEnumField(value: self.livenessThreshold, fieldNumber: 4)
    }
    if let v = self._compression {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }
    if self.doIncludeToken != false {
      try visitor.visitSingularBoolField(value: self.doIncludeToken, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Video_AuthenticateConfig, rhs: Sensory_Api_V1_Video_AuthenticateConfig) -> Bool {
    if lhs.authID != rhs.authID {return false}
    if lhs.isLivenessEnabled != rhs.isLivenessEnabled {return false}
    if lhs.livenessThreshold != rhs.livenessThreshold {return false}
    if lhs._compression != rhs._compression {return false}
    if lhs.doIncludeToken != rhs.doIncludeToken {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Video_ValidateRecognitionConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ValidateRecognitionConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "modelName"),
    2: .same(proto: "userId"),
    3: .same(proto: "threshold"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.modelName) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.userID) }()
      case 3: try { try decoder.decodeSingularEnumField(value: &self.threshold) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.modelName.isEmpty {
      try visitor.visitSingularStringField(value: self.modelName, fieldNumber: 1)
    }
    if !self.userID.isEmpty {
      try visitor.visitSingularStringField(value: self.userID, fieldNumber: 2)
    }
    if self.threshold != .low {
      try visitor.visitSingularEnumField(value: self.threshold, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Video_ValidateRecognitionConfig, rhs: Sensory_Api_V1_Video_ValidateRecognitionConfig) -> Bool {
    if lhs.modelName != rhs.modelName {return false}
    if lhs.userID != rhs.userID {return false}
    if lhs.threshold != rhs.threshold {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
