//
// DO NOT EDIT.
//
// Generated by the protocol buffer compiler.
// Source: v1/video/video.proto
//

//
// Copyright 2018, gRPC Authors All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
import GRPC
import NIO
import NIOConcurrencyHelpers
import SwiftProtobuf


/// Handles the retrieval and management of video models
///
/// Usage: instantiate `Sensory_Api_V1_Video_VideoModelsClient`, then call methods of this protocol to make API calls.
public protocol Sensory_Api_V1_Video_VideoModelsClientProtocol: GRPCClient {
  var serviceName: String { get }
  var interceptors: Sensory_Api_V1_Video_VideoModelsClientInterceptorFactoryProtocol? { get }

  func getModels(
    _ request: Sensory_Api_V1_Video_GetModelsRequest,
    callOptions: CallOptions?
  ) -> UnaryCall<Sensory_Api_V1_Video_GetModelsRequest, Sensory_Api_V1_Video_GetModelsResponse>
}

extension Sensory_Api_V1_Video_VideoModelsClientProtocol {
  public var serviceName: String {
    return "sensory.api.v1.video.VideoModels"
  }

  /// Get available models for enrollment and authentication
  /// Authorization metadata is required {"authorization": "Bearer <TOKEN>"}
  ///
  /// - Parameters:
  ///   - request: Request to send to GetModels.
  ///   - callOptions: Call options.
  /// - Returns: A `UnaryCall` with futures for the metadata, status and response.
  public func getModels(
    _ request: Sensory_Api_V1_Video_GetModelsRequest,
    callOptions: CallOptions? = nil
  ) -> UnaryCall<Sensory_Api_V1_Video_GetModelsRequest, Sensory_Api_V1_Video_GetModelsResponse> {
    return self.makeUnaryCall(
      path: Sensory_Api_V1_Video_VideoModelsClientMetadata.Methods.getModels.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeGetModelsInterceptors() ?? []
    )
  }
}

#if compiler(>=5.6)
@available(*, deprecated)
extension Sensory_Api_V1_Video_VideoModelsClient: @unchecked Sendable {}
#endif // compiler(>=5.6)

@available(*, deprecated, renamed: "Sensory_Api_V1_Video_VideoModelsNIOClient")
public final class Sensory_Api_V1_Video_VideoModelsClient: Sensory_Api_V1_Video_VideoModelsClientProtocol {
  private let lock = Lock()
  private var _defaultCallOptions: CallOptions
  private var _interceptors: Sensory_Api_V1_Video_VideoModelsClientInterceptorFactoryProtocol?
  public let channel: GRPCChannel
  public var defaultCallOptions: CallOptions {
    get { self.lock.withLock { return self._defaultCallOptions } }
    set { self.lock.withLockVoid { self._defaultCallOptions = newValue } }
  }
  public var interceptors: Sensory_Api_V1_Video_VideoModelsClientInterceptorFactoryProtocol? {
    get { self.lock.withLock { return self._interceptors } }
    set { self.lock.withLockVoid { self._interceptors = newValue } }
  }

  /// Creates a client for the sensory.api.v1.video.VideoModels service.
  ///
  /// - Parameters:
  ///   - channel: `GRPCChannel` to the service host.
  ///   - defaultCallOptions: Options to use for each service call if the user doesn't provide them.
  ///   - interceptors: A factory providing interceptors for each RPC.
  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Sensory_Api_V1_Video_VideoModelsClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self._defaultCallOptions = defaultCallOptions
    self._interceptors = interceptors
  }
}

public struct Sensory_Api_V1_Video_VideoModelsNIOClient: Sensory_Api_V1_Video_VideoModelsClientProtocol {
  public var channel: GRPCChannel
  public var defaultCallOptions: CallOptions
  public var interceptors: Sensory_Api_V1_Video_VideoModelsClientInterceptorFactoryProtocol?

  /// Creates a client for the sensory.api.v1.video.VideoModels service.
  ///
  /// - Parameters:
  ///   - channel: `GRPCChannel` to the service host.
  ///   - defaultCallOptions: Options to use for each service call if the user doesn't provide them.
  ///   - interceptors: A factory providing interceptors for each RPC.
  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Sensory_Api_V1_Video_VideoModelsClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self.defaultCallOptions = defaultCallOptions
    self.interceptors = interceptors
  }
}

#if compiler(>=5.6)
/// Handles the retrieval and management of video models
@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
public protocol Sensory_Api_V1_Video_VideoModelsAsyncClientProtocol: GRPCClient {
  static var serviceDescriptor: GRPCServiceDescriptor { get }
  var interceptors: Sensory_Api_V1_Video_VideoModelsClientInterceptorFactoryProtocol? { get }

  func makeGetModelsCall(
    _ request: Sensory_Api_V1_Video_GetModelsRequest,
    callOptions: CallOptions?
  ) -> GRPCAsyncUnaryCall<Sensory_Api_V1_Video_GetModelsRequest, Sensory_Api_V1_Video_GetModelsResponse>
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Sensory_Api_V1_Video_VideoModelsAsyncClientProtocol {
  public static var serviceDescriptor: GRPCServiceDescriptor {
    return Sensory_Api_V1_Video_VideoModelsClientMetadata.serviceDescriptor
  }

  public var interceptors: Sensory_Api_V1_Video_VideoModelsClientInterceptorFactoryProtocol? {
    return nil
  }

  public func makeGetModelsCall(
    _ request: Sensory_Api_V1_Video_GetModelsRequest,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncUnaryCall<Sensory_Api_V1_Video_GetModelsRequest, Sensory_Api_V1_Video_GetModelsResponse> {
    return self.makeAsyncUnaryCall(
      path: Sensory_Api_V1_Video_VideoModelsClientMetadata.Methods.getModels.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeGetModelsInterceptors() ?? []
    )
  }
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Sensory_Api_V1_Video_VideoModelsAsyncClientProtocol {
  public func getModels(
    _ request: Sensory_Api_V1_Video_GetModelsRequest,
    callOptions: CallOptions? = nil
  ) async throws -> Sensory_Api_V1_Video_GetModelsResponse {
    return try await self.performAsyncUnaryCall(
      path: Sensory_Api_V1_Video_VideoModelsClientMetadata.Methods.getModels.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeGetModelsInterceptors() ?? []
    )
  }
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
public struct Sensory_Api_V1_Video_VideoModelsAsyncClient: Sensory_Api_V1_Video_VideoModelsAsyncClientProtocol {
  public var channel: GRPCChannel
  public var defaultCallOptions: CallOptions
  public var interceptors: Sensory_Api_V1_Video_VideoModelsClientInterceptorFactoryProtocol?

  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Sensory_Api_V1_Video_VideoModelsClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self.defaultCallOptions = defaultCallOptions
    self.interceptors = interceptors
  }
}

#endif // compiler(>=5.6)

public protocol Sensory_Api_V1_Video_VideoModelsClientInterceptorFactoryProtocol: GRPCSendable {

  /// - Returns: Interceptors to use when invoking 'getModels'.
  func makeGetModelsInterceptors() -> [ClientInterceptor<Sensory_Api_V1_Video_GetModelsRequest, Sensory_Api_V1_Video_GetModelsResponse>]
}

public enum Sensory_Api_V1_Video_VideoModelsClientMetadata {
  public static let serviceDescriptor = GRPCServiceDescriptor(
    name: "VideoModels",
    fullName: "sensory.api.v1.video.VideoModels",
    methods: [
      Sensory_Api_V1_Video_VideoModelsClientMetadata.Methods.getModels,
    ]
  )

  public enum Methods {
    public static let getModels = GRPCMethodDescriptor(
      name: "GetModels",
      path: "/sensory.api.v1.video.VideoModels/GetModels",
      type: GRPCCallType.unary
    )
  }
}

#if compiler(>=5.6)
@available(swift, deprecated: 5.6)
extension Sensory_Api_V1_Video_VideoModelsTestClient: @unchecked Sendable {}
#endif // compiler(>=5.6)

@available(swift, deprecated: 5.6, message: "Test clients are not Sendable but the 'GRPCClient' API requires clients to be Sendable. Using a localhost client and server is the recommended alternative.")
public final class Sensory_Api_V1_Video_VideoModelsTestClient: Sensory_Api_V1_Video_VideoModelsClientProtocol {
  private let fakeChannel: FakeChannel
  public var defaultCallOptions: CallOptions
  public var interceptors: Sensory_Api_V1_Video_VideoModelsClientInterceptorFactoryProtocol?

  public var channel: GRPCChannel {
    return self.fakeChannel
  }

  public init(
    fakeChannel: FakeChannel = FakeChannel(),
    defaultCallOptions callOptions: CallOptions = CallOptions(),
    interceptors: Sensory_Api_V1_Video_VideoModelsClientInterceptorFactoryProtocol? = nil
  ) {
    self.fakeChannel = fakeChannel
    self.defaultCallOptions = callOptions
    self.interceptors = interceptors
  }

  /// Make a unary response for the GetModels RPC. This must be called
  /// before calling 'getModels'. See also 'FakeUnaryResponse'.
  ///
  /// - Parameter requestHandler: a handler for request parts sent by the RPC.
  public func makeGetModelsResponseStream(
    _ requestHandler: @escaping (FakeRequestPart<Sensory_Api_V1_Video_GetModelsRequest>) -> () = { _ in }
  ) -> FakeUnaryResponse<Sensory_Api_V1_Video_GetModelsRequest, Sensory_Api_V1_Video_GetModelsResponse> {
    return self.fakeChannel.makeFakeUnaryResponse(path: Sensory_Api_V1_Video_VideoModelsClientMetadata.Methods.getModels.path, requestHandler: requestHandler)
  }

  public func enqueueGetModelsResponse(
    _ response: Sensory_Api_V1_Video_GetModelsResponse,
    _ requestHandler: @escaping (FakeRequestPart<Sensory_Api_V1_Video_GetModelsRequest>) -> () = { _ in }
  ) {
    let stream = self.makeGetModelsResponseStream(requestHandler)
    // This is the only operation on the stream; try! is fine.
    try! stream.sendMessage(response)
  }

  /// Returns true if there are response streams enqueued for 'GetModels'
  public var hasGetModelsResponsesRemaining: Bool {
    return self.fakeChannel.hasFakeResponseEnqueued(forPath: Sensory_Api_V1_Video_VideoModelsClientMetadata.Methods.getModels.path)
  }
}

/// Handles all video-related biometrics
///
/// Usage: instantiate `Sensory_Api_V1_Video_VideoBiometricsClient`, then call methods of this protocol to make API calls.
public protocol Sensory_Api_V1_Video_VideoBiometricsClientProtocol: GRPCClient {
  var serviceName: String { get }
  var interceptors: Sensory_Api_V1_Video_VideoBiometricsClientInterceptorFactoryProtocol? { get }

  func createEnrollment(
    callOptions: CallOptions?,
    handler: @escaping (Sensory_Api_V1_Video_CreateEnrollmentResponse) -> Void
  ) -> BidirectionalStreamingCall<Sensory_Api_V1_Video_CreateEnrollmentRequest, Sensory_Api_V1_Video_CreateEnrollmentResponse>

  func authenticate(
    callOptions: CallOptions?,
    handler: @escaping (Sensory_Api_V1_Video_AuthenticateResponse) -> Void
  ) -> BidirectionalStreamingCall<Sensory_Api_V1_Video_AuthenticateRequest, Sensory_Api_V1_Video_AuthenticateResponse>
}

extension Sensory_Api_V1_Video_VideoBiometricsClientProtocol {
  public var serviceName: String {
    return "sensory.api.v1.video.VideoBiometrics"
  }

  /// Enrolls a user with a stream of video. Streams a CreateEnrollmentResponse
  /// as the video is processed.
  /// Authorization metadata is required {"authorization": "Bearer <TOKEN>"}
  ///
  /// Callers should use the `send` method on the returned object to send messages
  /// to the server. The caller should send an `.end` after the final message has been sent.
  ///
  /// - Parameters:
  ///   - callOptions: Call options.
  ///   - handler: A closure called when each response is received from the server.
  /// - Returns: A `ClientStreamingCall` with futures for the metadata and status.
  public func createEnrollment(
    callOptions: CallOptions? = nil,
    handler: @escaping (Sensory_Api_V1_Video_CreateEnrollmentResponse) -> Void
  ) -> BidirectionalStreamingCall<Sensory_Api_V1_Video_CreateEnrollmentRequest, Sensory_Api_V1_Video_CreateEnrollmentResponse> {
    return self.makeBidirectionalStreamingCall(
      path: Sensory_Api_V1_Video_VideoBiometricsClientMetadata.Methods.createEnrollment.path,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeCreateEnrollmentInterceptors() ?? [],
      handler: handler
    )
  }

  /// Authenticates a user with a stream of video against an existing enrollment.
  /// Streams an AuthenticateResponse as the video is processed.
  /// Authorization metadata is required {"authorization": "Bearer <TOKEN>"}
  ///
  /// Callers should use the `send` method on the returned object to send messages
  /// to the server. The caller should send an `.end` after the final message has been sent.
  ///
  /// - Parameters:
  ///   - callOptions: Call options.
  ///   - handler: A closure called when each response is received from the server.
  /// - Returns: A `ClientStreamingCall` with futures for the metadata and status.
  public func authenticate(
    callOptions: CallOptions? = nil,
    handler: @escaping (Sensory_Api_V1_Video_AuthenticateResponse) -> Void
  ) -> BidirectionalStreamingCall<Sensory_Api_V1_Video_AuthenticateRequest, Sensory_Api_V1_Video_AuthenticateResponse> {
    return self.makeBidirectionalStreamingCall(
      path: Sensory_Api_V1_Video_VideoBiometricsClientMetadata.Methods.authenticate.path,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeAuthenticateInterceptors() ?? [],
      handler: handler
    )
  }
}

#if compiler(>=5.6)
@available(*, deprecated)
extension Sensory_Api_V1_Video_VideoBiometricsClient: @unchecked Sendable {}
#endif // compiler(>=5.6)

@available(*, deprecated, renamed: "Sensory_Api_V1_Video_VideoBiometricsNIOClient")
public final class Sensory_Api_V1_Video_VideoBiometricsClient: Sensory_Api_V1_Video_VideoBiometricsClientProtocol {
  private let lock = Lock()
  private var _defaultCallOptions: CallOptions
  private var _interceptors: Sensory_Api_V1_Video_VideoBiometricsClientInterceptorFactoryProtocol?
  public let channel: GRPCChannel
  public var defaultCallOptions: CallOptions {
    get { self.lock.withLock { return self._defaultCallOptions } }
    set { self.lock.withLockVoid { self._defaultCallOptions = newValue } }
  }
  public var interceptors: Sensory_Api_V1_Video_VideoBiometricsClientInterceptorFactoryProtocol? {
    get { self.lock.withLock { return self._interceptors } }
    set { self.lock.withLockVoid { self._interceptors = newValue } }
  }

  /// Creates a client for the sensory.api.v1.video.VideoBiometrics service.
  ///
  /// - Parameters:
  ///   - channel: `GRPCChannel` to the service host.
  ///   - defaultCallOptions: Options to use for each service call if the user doesn't provide them.
  ///   - interceptors: A factory providing interceptors for each RPC.
  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Sensory_Api_V1_Video_VideoBiometricsClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self._defaultCallOptions = defaultCallOptions
    self._interceptors = interceptors
  }
}

public struct Sensory_Api_V1_Video_VideoBiometricsNIOClient: Sensory_Api_V1_Video_VideoBiometricsClientProtocol {
  public var channel: GRPCChannel
  public var defaultCallOptions: CallOptions
  public var interceptors: Sensory_Api_V1_Video_VideoBiometricsClientInterceptorFactoryProtocol?

  /// Creates a client for the sensory.api.v1.video.VideoBiometrics service.
  ///
  /// - Parameters:
  ///   - channel: `GRPCChannel` to the service host.
  ///   - defaultCallOptions: Options to use for each service call if the user doesn't provide them.
  ///   - interceptors: A factory providing interceptors for each RPC.
  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Sensory_Api_V1_Video_VideoBiometricsClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self.defaultCallOptions = defaultCallOptions
    self.interceptors = interceptors
  }
}

#if compiler(>=5.6)
/// Handles all video-related biometrics
@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
public protocol Sensory_Api_V1_Video_VideoBiometricsAsyncClientProtocol: GRPCClient {
  static var serviceDescriptor: GRPCServiceDescriptor { get }
  var interceptors: Sensory_Api_V1_Video_VideoBiometricsClientInterceptorFactoryProtocol? { get }

  func makeCreateEnrollmentCall(
    callOptions: CallOptions?
  ) -> GRPCAsyncBidirectionalStreamingCall<Sensory_Api_V1_Video_CreateEnrollmentRequest, Sensory_Api_V1_Video_CreateEnrollmentResponse>

  func makeAuthenticateCall(
    callOptions: CallOptions?
  ) -> GRPCAsyncBidirectionalStreamingCall<Sensory_Api_V1_Video_AuthenticateRequest, Sensory_Api_V1_Video_AuthenticateResponse>
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Sensory_Api_V1_Video_VideoBiometricsAsyncClientProtocol {
  public static var serviceDescriptor: GRPCServiceDescriptor {
    return Sensory_Api_V1_Video_VideoBiometricsClientMetadata.serviceDescriptor
  }

  public var interceptors: Sensory_Api_V1_Video_VideoBiometricsClientInterceptorFactoryProtocol? {
    return nil
  }

  public func makeCreateEnrollmentCall(
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncBidirectionalStreamingCall<Sensory_Api_V1_Video_CreateEnrollmentRequest, Sensory_Api_V1_Video_CreateEnrollmentResponse> {
    return self.makeAsyncBidirectionalStreamingCall(
      path: Sensory_Api_V1_Video_VideoBiometricsClientMetadata.Methods.createEnrollment.path,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeCreateEnrollmentInterceptors() ?? []
    )
  }

  public func makeAuthenticateCall(
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncBidirectionalStreamingCall<Sensory_Api_V1_Video_AuthenticateRequest, Sensory_Api_V1_Video_AuthenticateResponse> {
    return self.makeAsyncBidirectionalStreamingCall(
      path: Sensory_Api_V1_Video_VideoBiometricsClientMetadata.Methods.authenticate.path,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeAuthenticateInterceptors() ?? []
    )
  }
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Sensory_Api_V1_Video_VideoBiometricsAsyncClientProtocol {
  public func createEnrollment<RequestStream>(
    _ requests: RequestStream,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncResponseStream<Sensory_Api_V1_Video_CreateEnrollmentResponse> where RequestStream: Sequence, RequestStream.Element == Sensory_Api_V1_Video_CreateEnrollmentRequest {
    return self.performAsyncBidirectionalStreamingCall(
      path: Sensory_Api_V1_Video_VideoBiometricsClientMetadata.Methods.createEnrollment.path,
      requests: requests,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeCreateEnrollmentInterceptors() ?? []
    )
  }

  public func createEnrollment<RequestStream>(
    _ requests: RequestStream,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncResponseStream<Sensory_Api_V1_Video_CreateEnrollmentResponse> where RequestStream: AsyncSequence & Sendable, RequestStream.Element == Sensory_Api_V1_Video_CreateEnrollmentRequest {
    return self.performAsyncBidirectionalStreamingCall(
      path: Sensory_Api_V1_Video_VideoBiometricsClientMetadata.Methods.createEnrollment.path,
      requests: requests,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeCreateEnrollmentInterceptors() ?? []
    )
  }

  public func authenticate<RequestStream>(
    _ requests: RequestStream,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncResponseStream<Sensory_Api_V1_Video_AuthenticateResponse> where RequestStream: Sequence, RequestStream.Element == Sensory_Api_V1_Video_AuthenticateRequest {
    return self.performAsyncBidirectionalStreamingCall(
      path: Sensory_Api_V1_Video_VideoBiometricsClientMetadata.Methods.authenticate.path,
      requests: requests,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeAuthenticateInterceptors() ?? []
    )
  }

  public func authenticate<RequestStream>(
    _ requests: RequestStream,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncResponseStream<Sensory_Api_V1_Video_AuthenticateResponse> where RequestStream: AsyncSequence & Sendable, RequestStream.Element == Sensory_Api_V1_Video_AuthenticateRequest {
    return self.performAsyncBidirectionalStreamingCall(
      path: Sensory_Api_V1_Video_VideoBiometricsClientMetadata.Methods.authenticate.path,
      requests: requests,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeAuthenticateInterceptors() ?? []
    )
  }
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
public struct Sensory_Api_V1_Video_VideoBiometricsAsyncClient: Sensory_Api_V1_Video_VideoBiometricsAsyncClientProtocol {
  public var channel: GRPCChannel
  public var defaultCallOptions: CallOptions
  public var interceptors: Sensory_Api_V1_Video_VideoBiometricsClientInterceptorFactoryProtocol?

  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Sensory_Api_V1_Video_VideoBiometricsClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self.defaultCallOptions = defaultCallOptions
    self.interceptors = interceptors
  }
}

#endif // compiler(>=5.6)

public protocol Sensory_Api_V1_Video_VideoBiometricsClientInterceptorFactoryProtocol: GRPCSendable {

  /// - Returns: Interceptors to use when invoking 'createEnrollment'.
  func makeCreateEnrollmentInterceptors() -> [ClientInterceptor<Sensory_Api_V1_Video_CreateEnrollmentRequest, Sensory_Api_V1_Video_CreateEnrollmentResponse>]

  /// - Returns: Interceptors to use when invoking 'authenticate'.
  func makeAuthenticateInterceptors() -> [ClientInterceptor<Sensory_Api_V1_Video_AuthenticateRequest, Sensory_Api_V1_Video_AuthenticateResponse>]
}

public enum Sensory_Api_V1_Video_VideoBiometricsClientMetadata {
  public static let serviceDescriptor = GRPCServiceDescriptor(
    name: "VideoBiometrics",
    fullName: "sensory.api.v1.video.VideoBiometrics",
    methods: [
      Sensory_Api_V1_Video_VideoBiometricsClientMetadata.Methods.createEnrollment,
      Sensory_Api_V1_Video_VideoBiometricsClientMetadata.Methods.authenticate,
    ]
  )

  public enum Methods {
    public static let createEnrollment = GRPCMethodDescriptor(
      name: "CreateEnrollment",
      path: "/sensory.api.v1.video.VideoBiometrics/CreateEnrollment",
      type: GRPCCallType.bidirectionalStreaming
    )

    public static let authenticate = GRPCMethodDescriptor(
      name: "Authenticate",
      path: "/sensory.api.v1.video.VideoBiometrics/Authenticate",
      type: GRPCCallType.bidirectionalStreaming
    )
  }
}

#if compiler(>=5.6)
@available(swift, deprecated: 5.6)
extension Sensory_Api_V1_Video_VideoBiometricsTestClient: @unchecked Sendable {}
#endif // compiler(>=5.6)

@available(swift, deprecated: 5.6, message: "Test clients are not Sendable but the 'GRPCClient' API requires clients to be Sendable. Using a localhost client and server is the recommended alternative.")
public final class Sensory_Api_V1_Video_VideoBiometricsTestClient: Sensory_Api_V1_Video_VideoBiometricsClientProtocol {
  private let fakeChannel: FakeChannel
  public var defaultCallOptions: CallOptions
  public var interceptors: Sensory_Api_V1_Video_VideoBiometricsClientInterceptorFactoryProtocol?

  public var channel: GRPCChannel {
    return self.fakeChannel
  }

  public init(
    fakeChannel: FakeChannel = FakeChannel(),
    defaultCallOptions callOptions: CallOptions = CallOptions(),
    interceptors: Sensory_Api_V1_Video_VideoBiometricsClientInterceptorFactoryProtocol? = nil
  ) {
    self.fakeChannel = fakeChannel
    self.defaultCallOptions = callOptions
    self.interceptors = interceptors
  }

  /// Make a streaming response for the CreateEnrollment RPC. This must be called
  /// before calling 'createEnrollment'. See also 'FakeStreamingResponse'.
  ///
  /// - Parameter requestHandler: a handler for request parts sent by the RPC.
  public func makeCreateEnrollmentResponseStream(
    _ requestHandler: @escaping (FakeRequestPart<Sensory_Api_V1_Video_CreateEnrollmentRequest>) -> () = { _ in }
  ) -> FakeStreamingResponse<Sensory_Api_V1_Video_CreateEnrollmentRequest, Sensory_Api_V1_Video_CreateEnrollmentResponse> {
    return self.fakeChannel.makeFakeStreamingResponse(path: Sensory_Api_V1_Video_VideoBiometricsClientMetadata.Methods.createEnrollment.path, requestHandler: requestHandler)
  }

  public func enqueueCreateEnrollmentResponses(
    _ responses: [Sensory_Api_V1_Video_CreateEnrollmentResponse],
    _ requestHandler: @escaping (FakeRequestPart<Sensory_Api_V1_Video_CreateEnrollmentRequest>) -> () = { _ in }
  ) {
    let stream = self.makeCreateEnrollmentResponseStream(requestHandler)
    // These are the only operation on the stream; try! is fine.
    responses.forEach { try! stream.sendMessage($0) }
    try! stream.sendEnd()
  }

  /// Returns true if there are response streams enqueued for 'CreateEnrollment'
  public var hasCreateEnrollmentResponsesRemaining: Bool {
    return self.fakeChannel.hasFakeResponseEnqueued(forPath: Sensory_Api_V1_Video_VideoBiometricsClientMetadata.Methods.createEnrollment.path)
  }

  /// Make a streaming response for the Authenticate RPC. This must be called
  /// before calling 'authenticate'. See also 'FakeStreamingResponse'.
  ///
  /// - Parameter requestHandler: a handler for request parts sent by the RPC.
  public func makeAuthenticateResponseStream(
    _ requestHandler: @escaping (FakeRequestPart<Sensory_Api_V1_Video_AuthenticateRequest>) -> () = { _ in }
  ) -> FakeStreamingResponse<Sensory_Api_V1_Video_AuthenticateRequest, Sensory_Api_V1_Video_AuthenticateResponse> {
    return self.fakeChannel.makeFakeStreamingResponse(path: Sensory_Api_V1_Video_VideoBiometricsClientMetadata.Methods.authenticate.path, requestHandler: requestHandler)
  }

  public func enqueueAuthenticateResponses(
    _ responses: [Sensory_Api_V1_Video_AuthenticateResponse],
    _ requestHandler: @escaping (FakeRequestPart<Sensory_Api_V1_Video_AuthenticateRequest>) -> () = { _ in }
  ) {
    let stream = self.makeAuthenticateResponseStream(requestHandler)
    // These are the only operation on the stream; try! is fine.
    responses.forEach { try! stream.sendMessage($0) }
    try! stream.sendEnd()
  }

  /// Returns true if there are response streams enqueued for 'Authenticate'
  public var hasAuthenticateResponsesRemaining: Bool {
    return self.fakeChannel.hasFakeResponseEnqueued(forPath: Sensory_Api_V1_Video_VideoBiometricsClientMetadata.Methods.authenticate.path)
  }
}

/// Handles all video recognition endpoints
///
/// Usage: instantiate `Sensory_Api_V1_Video_VideoRecognitionClient`, then call methods of this protocol to make API calls.
public protocol Sensory_Api_V1_Video_VideoRecognitionClientProtocol: GRPCClient {
  var serviceName: String { get }
  var interceptors: Sensory_Api_V1_Video_VideoRecognitionClientInterceptorFactoryProtocol? { get }

  func validateLiveness(
    callOptions: CallOptions?,
    handler: @escaping (Sensory_Api_V1_Video_LivenessRecognitionResponse) -> Void
  ) -> BidirectionalStreamingCall<Sensory_Api_V1_Video_ValidateRecognitionRequest, Sensory_Api_V1_Video_LivenessRecognitionResponse>
}

extension Sensory_Api_V1_Video_VideoRecognitionClientProtocol {
  public var serviceName: String {
    return "sensory.api.v1.video.VideoRecognition"
  }

  /// Validates the liveness of a single image or stream of images.
  /// Streams a ValidateRecognitionResponse as the images are processed.
  /// Authorization metadata is required {"authorization": "Bearer <TOKEN>"}
  ///
  /// Callers should use the `send` method on the returned object to send messages
  /// to the server. The caller should send an `.end` after the final message has been sent.
  ///
  /// - Parameters:
  ///   - callOptions: Call options.
  ///   - handler: A closure called when each response is received from the server.
  /// - Returns: A `ClientStreamingCall` with futures for the metadata and status.
  public func validateLiveness(
    callOptions: CallOptions? = nil,
    handler: @escaping (Sensory_Api_V1_Video_LivenessRecognitionResponse) -> Void
  ) -> BidirectionalStreamingCall<Sensory_Api_V1_Video_ValidateRecognitionRequest, Sensory_Api_V1_Video_LivenessRecognitionResponse> {
    return self.makeBidirectionalStreamingCall(
      path: Sensory_Api_V1_Video_VideoRecognitionClientMetadata.Methods.validateLiveness.path,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeValidateLivenessInterceptors() ?? [],
      handler: handler
    )
  }
}

#if compiler(>=5.6)
@available(*, deprecated)
extension Sensory_Api_V1_Video_VideoRecognitionClient: @unchecked Sendable {}
#endif // compiler(>=5.6)

@available(*, deprecated, renamed: "Sensory_Api_V1_Video_VideoRecognitionNIOClient")
public final class Sensory_Api_V1_Video_VideoRecognitionClient: Sensory_Api_V1_Video_VideoRecognitionClientProtocol {
  private let lock = Lock()
  private var _defaultCallOptions: CallOptions
  private var _interceptors: Sensory_Api_V1_Video_VideoRecognitionClientInterceptorFactoryProtocol?
  public let channel: GRPCChannel
  public var defaultCallOptions: CallOptions {
    get { self.lock.withLock { return self._defaultCallOptions } }
    set { self.lock.withLockVoid { self._defaultCallOptions = newValue } }
  }
  public var interceptors: Sensory_Api_V1_Video_VideoRecognitionClientInterceptorFactoryProtocol? {
    get { self.lock.withLock { return self._interceptors } }
    set { self.lock.withLockVoid { self._interceptors = newValue } }
  }

  /// Creates a client for the sensory.api.v1.video.VideoRecognition service.
  ///
  /// - Parameters:
  ///   - channel: `GRPCChannel` to the service host.
  ///   - defaultCallOptions: Options to use for each service call if the user doesn't provide them.
  ///   - interceptors: A factory providing interceptors for each RPC.
  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Sensory_Api_V1_Video_VideoRecognitionClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self._defaultCallOptions = defaultCallOptions
    self._interceptors = interceptors
  }
}

public struct Sensory_Api_V1_Video_VideoRecognitionNIOClient: Sensory_Api_V1_Video_VideoRecognitionClientProtocol {
  public var channel: GRPCChannel
  public var defaultCallOptions: CallOptions
  public var interceptors: Sensory_Api_V1_Video_VideoRecognitionClientInterceptorFactoryProtocol?

  /// Creates a client for the sensory.api.v1.video.VideoRecognition service.
  ///
  /// - Parameters:
  ///   - channel: `GRPCChannel` to the service host.
  ///   - defaultCallOptions: Options to use for each service call if the user doesn't provide them.
  ///   - interceptors: A factory providing interceptors for each RPC.
  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Sensory_Api_V1_Video_VideoRecognitionClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self.defaultCallOptions = defaultCallOptions
    self.interceptors = interceptors
  }
}

#if compiler(>=5.6)
/// Handles all video recognition endpoints
@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
public protocol Sensory_Api_V1_Video_VideoRecognitionAsyncClientProtocol: GRPCClient {
  static var serviceDescriptor: GRPCServiceDescriptor { get }
  var interceptors: Sensory_Api_V1_Video_VideoRecognitionClientInterceptorFactoryProtocol? { get }

  func makeValidateLivenessCall(
    callOptions: CallOptions?
  ) -> GRPCAsyncBidirectionalStreamingCall<Sensory_Api_V1_Video_ValidateRecognitionRequest, Sensory_Api_V1_Video_LivenessRecognitionResponse>
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Sensory_Api_V1_Video_VideoRecognitionAsyncClientProtocol {
  public static var serviceDescriptor: GRPCServiceDescriptor {
    return Sensory_Api_V1_Video_VideoRecognitionClientMetadata.serviceDescriptor
  }

  public var interceptors: Sensory_Api_V1_Video_VideoRecognitionClientInterceptorFactoryProtocol? {
    return nil
  }

  public func makeValidateLivenessCall(
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncBidirectionalStreamingCall<Sensory_Api_V1_Video_ValidateRecognitionRequest, Sensory_Api_V1_Video_LivenessRecognitionResponse> {
    return self.makeAsyncBidirectionalStreamingCall(
      path: Sensory_Api_V1_Video_VideoRecognitionClientMetadata.Methods.validateLiveness.path,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeValidateLivenessInterceptors() ?? []
    )
  }
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Sensory_Api_V1_Video_VideoRecognitionAsyncClientProtocol {
  public func validateLiveness<RequestStream>(
    _ requests: RequestStream,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncResponseStream<Sensory_Api_V1_Video_LivenessRecognitionResponse> where RequestStream: Sequence, RequestStream.Element == Sensory_Api_V1_Video_ValidateRecognitionRequest {
    return self.performAsyncBidirectionalStreamingCall(
      path: Sensory_Api_V1_Video_VideoRecognitionClientMetadata.Methods.validateLiveness.path,
      requests: requests,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeValidateLivenessInterceptors() ?? []
    )
  }

  public func validateLiveness<RequestStream>(
    _ requests: RequestStream,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncResponseStream<Sensory_Api_V1_Video_LivenessRecognitionResponse> where RequestStream: AsyncSequence & Sendable, RequestStream.Element == Sensory_Api_V1_Video_ValidateRecognitionRequest {
    return self.performAsyncBidirectionalStreamingCall(
      path: Sensory_Api_V1_Video_VideoRecognitionClientMetadata.Methods.validateLiveness.path,
      requests: requests,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeValidateLivenessInterceptors() ?? []
    )
  }
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
public struct Sensory_Api_V1_Video_VideoRecognitionAsyncClient: Sensory_Api_V1_Video_VideoRecognitionAsyncClientProtocol {
  public var channel: GRPCChannel
  public var defaultCallOptions: CallOptions
  public var interceptors: Sensory_Api_V1_Video_VideoRecognitionClientInterceptorFactoryProtocol?

  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Sensory_Api_V1_Video_VideoRecognitionClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self.defaultCallOptions = defaultCallOptions
    self.interceptors = interceptors
  }
}

#endif // compiler(>=5.6)

public protocol Sensory_Api_V1_Video_VideoRecognitionClientInterceptorFactoryProtocol: GRPCSendable {

  /// - Returns: Interceptors to use when invoking 'validateLiveness'.
  func makeValidateLivenessInterceptors() -> [ClientInterceptor<Sensory_Api_V1_Video_ValidateRecognitionRequest, Sensory_Api_V1_Video_LivenessRecognitionResponse>]
}

public enum Sensory_Api_V1_Video_VideoRecognitionClientMetadata {
  public static let serviceDescriptor = GRPCServiceDescriptor(
    name: "VideoRecognition",
    fullName: "sensory.api.v1.video.VideoRecognition",
    methods: [
      Sensory_Api_V1_Video_VideoRecognitionClientMetadata.Methods.validateLiveness,
    ]
  )

  public enum Methods {
    public static let validateLiveness = GRPCMethodDescriptor(
      name: "ValidateLiveness",
      path: "/sensory.api.v1.video.VideoRecognition/ValidateLiveness",
      type: GRPCCallType.bidirectionalStreaming
    )
  }
}

#if compiler(>=5.6)
@available(swift, deprecated: 5.6)
extension Sensory_Api_V1_Video_VideoRecognitionTestClient: @unchecked Sendable {}
#endif // compiler(>=5.6)

@available(swift, deprecated: 5.6, message: "Test clients are not Sendable but the 'GRPCClient' API requires clients to be Sendable. Using a localhost client and server is the recommended alternative.")
public final class Sensory_Api_V1_Video_VideoRecognitionTestClient: Sensory_Api_V1_Video_VideoRecognitionClientProtocol {
  private let fakeChannel: FakeChannel
  public var defaultCallOptions: CallOptions
  public var interceptors: Sensory_Api_V1_Video_VideoRecognitionClientInterceptorFactoryProtocol?

  public var channel: GRPCChannel {
    return self.fakeChannel
  }

  public init(
    fakeChannel: FakeChannel = FakeChannel(),
    defaultCallOptions callOptions: CallOptions = CallOptions(),
    interceptors: Sensory_Api_V1_Video_VideoRecognitionClientInterceptorFactoryProtocol? = nil
  ) {
    self.fakeChannel = fakeChannel
    self.defaultCallOptions = callOptions
    self.interceptors = interceptors
  }

  /// Make a streaming response for the ValidateLiveness RPC. This must be called
  /// before calling 'validateLiveness'. See also 'FakeStreamingResponse'.
  ///
  /// - Parameter requestHandler: a handler for request parts sent by the RPC.
  public func makeValidateLivenessResponseStream(
    _ requestHandler: @escaping (FakeRequestPart<Sensory_Api_V1_Video_ValidateRecognitionRequest>) -> () = { _ in }
  ) -> FakeStreamingResponse<Sensory_Api_V1_Video_ValidateRecognitionRequest, Sensory_Api_V1_Video_LivenessRecognitionResponse> {
    return self.fakeChannel.makeFakeStreamingResponse(path: Sensory_Api_V1_Video_VideoRecognitionClientMetadata.Methods.validateLiveness.path, requestHandler: requestHandler)
  }

  public func enqueueValidateLivenessResponses(
    _ responses: [Sensory_Api_V1_Video_LivenessRecognitionResponse],
    _ requestHandler: @escaping (FakeRequestPart<Sensory_Api_V1_Video_ValidateRecognitionRequest>) -> () = { _ in }
  ) {
    let stream = self.makeValidateLivenessResponseStream(requestHandler)
    // These are the only operation on the stream; try! is fine.
    responses.forEach { try! stream.sendMessage($0) }
    try! stream.sendEnd()
  }

  /// Returns true if there are response streams enqueued for 'ValidateLiveness'
  public var hasValidateLivenessResponsesRemaining: Bool {
    return self.fakeChannel.hasFakeResponseEnqueued(forPath: Sensory_Api_V1_Video_VideoRecognitionClientMetadata.Methods.validateLiveness.path)
  }
}

/// Handles the retrieval and management of video models
///
/// To build a server, implement a class that conforms to this protocol.
public protocol Sensory_Api_V1_Video_VideoModelsProvider: CallHandlerProvider {
  var interceptors: Sensory_Api_V1_Video_VideoModelsServerInterceptorFactoryProtocol? { get }

  /// Get available models for enrollment and authentication
  /// Authorization metadata is required {"authorization": "Bearer <TOKEN>"}
  func getModels(request: Sensory_Api_V1_Video_GetModelsRequest, context: StatusOnlyCallContext) -> EventLoopFuture<Sensory_Api_V1_Video_GetModelsResponse>
}

extension Sensory_Api_V1_Video_VideoModelsProvider {
  public var serviceName: Substring {
    return Sensory_Api_V1_Video_VideoModelsServerMetadata.serviceDescriptor.fullName[...]
  }

  /// Determines, calls and returns the appropriate request handler, depending on the request's method.
  /// Returns nil for methods not handled by this service.
  public func handle(
    method name: Substring,
    context: CallHandlerContext
  ) -> GRPCServerHandlerProtocol? {
    switch name {
    case "GetModels":
      return UnaryServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Sensory_Api_V1_Video_GetModelsRequest>(),
        responseSerializer: ProtobufSerializer<Sensory_Api_V1_Video_GetModelsResponse>(),
        interceptors: self.interceptors?.makeGetModelsInterceptors() ?? [],
        userFunction: self.getModels(request:context:)
      )

    default:
      return nil
    }
  }
}

#if compiler(>=5.6)

/// Handles the retrieval and management of video models
///
/// To implement a server, implement an object which conforms to this protocol.
@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
public protocol Sensory_Api_V1_Video_VideoModelsAsyncProvider: CallHandlerProvider {
  static var serviceDescriptor: GRPCServiceDescriptor { get }
  var interceptors: Sensory_Api_V1_Video_VideoModelsServerInterceptorFactoryProtocol? { get }

  /// Get available models for enrollment and authentication
  /// Authorization metadata is required {"authorization": "Bearer <TOKEN>"}
  @Sendable func getModels(
    request: Sensory_Api_V1_Video_GetModelsRequest,
    context: GRPCAsyncServerCallContext
  ) async throws -> Sensory_Api_V1_Video_GetModelsResponse
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Sensory_Api_V1_Video_VideoModelsAsyncProvider {
  public static var serviceDescriptor: GRPCServiceDescriptor {
    return Sensory_Api_V1_Video_VideoModelsServerMetadata.serviceDescriptor
  }

  public var serviceName: Substring {
    return Sensory_Api_V1_Video_VideoModelsServerMetadata.serviceDescriptor.fullName[...]
  }

  public var interceptors: Sensory_Api_V1_Video_VideoModelsServerInterceptorFactoryProtocol? {
    return nil
  }

  public func handle(
    method name: Substring,
    context: CallHandlerContext
  ) -> GRPCServerHandlerProtocol? {
    switch name {
    case "GetModels":
      return GRPCAsyncServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Sensory_Api_V1_Video_GetModelsRequest>(),
        responseSerializer: ProtobufSerializer<Sensory_Api_V1_Video_GetModelsResponse>(),
        interceptors: self.interceptors?.makeGetModelsInterceptors() ?? [],
        wrapping: self.getModels(request:context:)
      )

    default:
      return nil
    }
  }
}

#endif // compiler(>=5.6)

public protocol Sensory_Api_V1_Video_VideoModelsServerInterceptorFactoryProtocol {

  /// - Returns: Interceptors to use when handling 'getModels'.
  ///   Defaults to calling `self.makeInterceptors()`.
  func makeGetModelsInterceptors() -> [ServerInterceptor<Sensory_Api_V1_Video_GetModelsRequest, Sensory_Api_V1_Video_GetModelsResponse>]
}

public enum Sensory_Api_V1_Video_VideoModelsServerMetadata {
  public static let serviceDescriptor = GRPCServiceDescriptor(
    name: "VideoModels",
    fullName: "sensory.api.v1.video.VideoModels",
    methods: [
      Sensory_Api_V1_Video_VideoModelsServerMetadata.Methods.getModels,
    ]
  )

  public enum Methods {
    public static let getModels = GRPCMethodDescriptor(
      name: "GetModels",
      path: "/sensory.api.v1.video.VideoModels/GetModels",
      type: GRPCCallType.unary
    )
  }
}
/// Handles all video-related biometrics
///
/// To build a server, implement a class that conforms to this protocol.
public protocol Sensory_Api_V1_Video_VideoBiometricsProvider: CallHandlerProvider {
  var interceptors: Sensory_Api_V1_Video_VideoBiometricsServerInterceptorFactoryProtocol? { get }

  /// Enrolls a user with a stream of video. Streams a CreateEnrollmentResponse
  /// as the video is processed.
  /// Authorization metadata is required {"authorization": "Bearer <TOKEN>"}
  func createEnrollment(context: StreamingResponseCallContext<Sensory_Api_V1_Video_CreateEnrollmentResponse>) -> EventLoopFuture<(StreamEvent<Sensory_Api_V1_Video_CreateEnrollmentRequest>) -> Void>

  /// Authenticates a user with a stream of video against an existing enrollment.
  /// Streams an AuthenticateResponse as the video is processed.
  /// Authorization metadata is required {"authorization": "Bearer <TOKEN>"}
  func authenticate(context: StreamingResponseCallContext<Sensory_Api_V1_Video_AuthenticateResponse>) -> EventLoopFuture<(StreamEvent<Sensory_Api_V1_Video_AuthenticateRequest>) -> Void>
}

extension Sensory_Api_V1_Video_VideoBiometricsProvider {
  public var serviceName: Substring {
    return Sensory_Api_V1_Video_VideoBiometricsServerMetadata.serviceDescriptor.fullName[...]
  }

  /// Determines, calls and returns the appropriate request handler, depending on the request's method.
  /// Returns nil for methods not handled by this service.
  public func handle(
    method name: Substring,
    context: CallHandlerContext
  ) -> GRPCServerHandlerProtocol? {
    switch name {
    case "CreateEnrollment":
      return BidirectionalStreamingServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Sensory_Api_V1_Video_CreateEnrollmentRequest>(),
        responseSerializer: ProtobufSerializer<Sensory_Api_V1_Video_CreateEnrollmentResponse>(),
        interceptors: self.interceptors?.makeCreateEnrollmentInterceptors() ?? [],
        observerFactory: self.createEnrollment(context:)
      )

    case "Authenticate":
      return BidirectionalStreamingServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Sensory_Api_V1_Video_AuthenticateRequest>(),
        responseSerializer: ProtobufSerializer<Sensory_Api_V1_Video_AuthenticateResponse>(),
        interceptors: self.interceptors?.makeAuthenticateInterceptors() ?? [],
        observerFactory: self.authenticate(context:)
      )

    default:
      return nil
    }
  }
}

#if compiler(>=5.6)

/// Handles all video-related biometrics
///
/// To implement a server, implement an object which conforms to this protocol.
@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
public protocol Sensory_Api_V1_Video_VideoBiometricsAsyncProvider: CallHandlerProvider {
  static var serviceDescriptor: GRPCServiceDescriptor { get }
  var interceptors: Sensory_Api_V1_Video_VideoBiometricsServerInterceptorFactoryProtocol? { get }

  /// Enrolls a user with a stream of video. Streams a CreateEnrollmentResponse
  /// as the video is processed.
  /// Authorization metadata is required {"authorization": "Bearer <TOKEN>"}
  @Sendable func createEnrollment(
    requestStream: GRPCAsyncRequestStream<Sensory_Api_V1_Video_CreateEnrollmentRequest>,
    responseStream: GRPCAsyncResponseStreamWriter<Sensory_Api_V1_Video_CreateEnrollmentResponse>,
    context: GRPCAsyncServerCallContext
  ) async throws

  /// Authenticates a user with a stream of video against an existing enrollment.
  /// Streams an AuthenticateResponse as the video is processed.
  /// Authorization metadata is required {"authorization": "Bearer <TOKEN>"}
  @Sendable func authenticate(
    requestStream: GRPCAsyncRequestStream<Sensory_Api_V1_Video_AuthenticateRequest>,
    responseStream: GRPCAsyncResponseStreamWriter<Sensory_Api_V1_Video_AuthenticateResponse>,
    context: GRPCAsyncServerCallContext
  ) async throws
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Sensory_Api_V1_Video_VideoBiometricsAsyncProvider {
  public static var serviceDescriptor: GRPCServiceDescriptor {
    return Sensory_Api_V1_Video_VideoBiometricsServerMetadata.serviceDescriptor
  }

  public var serviceName: Substring {
    return Sensory_Api_V1_Video_VideoBiometricsServerMetadata.serviceDescriptor.fullName[...]
  }

  public var interceptors: Sensory_Api_V1_Video_VideoBiometricsServerInterceptorFactoryProtocol? {
    return nil
  }

  public func handle(
    method name: Substring,
    context: CallHandlerContext
  ) -> GRPCServerHandlerProtocol? {
    switch name {
    case "CreateEnrollment":
      return GRPCAsyncServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Sensory_Api_V1_Video_CreateEnrollmentRequest>(),
        responseSerializer: ProtobufSerializer<Sensory_Api_V1_Video_CreateEnrollmentResponse>(),
        interceptors: self.interceptors?.makeCreateEnrollmentInterceptors() ?? [],
        wrapping: self.createEnrollment(requestStream:responseStream:context:)
      )

    case "Authenticate":
      return GRPCAsyncServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Sensory_Api_V1_Video_AuthenticateRequest>(),
        responseSerializer: ProtobufSerializer<Sensory_Api_V1_Video_AuthenticateResponse>(),
        interceptors: self.interceptors?.makeAuthenticateInterceptors() ?? [],
        wrapping: self.authenticate(requestStream:responseStream:context:)
      )

    default:
      return nil
    }
  }
}

#endif // compiler(>=5.6)

public protocol Sensory_Api_V1_Video_VideoBiometricsServerInterceptorFactoryProtocol {

  /// - Returns: Interceptors to use when handling 'createEnrollment'.
  ///   Defaults to calling `self.makeInterceptors()`.
  func makeCreateEnrollmentInterceptors() -> [ServerInterceptor<Sensory_Api_V1_Video_CreateEnrollmentRequest, Sensory_Api_V1_Video_CreateEnrollmentResponse>]

  /// - Returns: Interceptors to use when handling 'authenticate'.
  ///   Defaults to calling `self.makeInterceptors()`.
  func makeAuthenticateInterceptors() -> [ServerInterceptor<Sensory_Api_V1_Video_AuthenticateRequest, Sensory_Api_V1_Video_AuthenticateResponse>]
}

public enum Sensory_Api_V1_Video_VideoBiometricsServerMetadata {
  public static let serviceDescriptor = GRPCServiceDescriptor(
    name: "VideoBiometrics",
    fullName: "sensory.api.v1.video.VideoBiometrics",
    methods: [
      Sensory_Api_V1_Video_VideoBiometricsServerMetadata.Methods.createEnrollment,
      Sensory_Api_V1_Video_VideoBiometricsServerMetadata.Methods.authenticate,
    ]
  )

  public enum Methods {
    public static let createEnrollment = GRPCMethodDescriptor(
      name: "CreateEnrollment",
      path: "/sensory.api.v1.video.VideoBiometrics/CreateEnrollment",
      type: GRPCCallType.bidirectionalStreaming
    )

    public static let authenticate = GRPCMethodDescriptor(
      name: "Authenticate",
      path: "/sensory.api.v1.video.VideoBiometrics/Authenticate",
      type: GRPCCallType.bidirectionalStreaming
    )
  }
}
/// Handles all video recognition endpoints
///
/// To build a server, implement a class that conforms to this protocol.
public protocol Sensory_Api_V1_Video_VideoRecognitionProvider: CallHandlerProvider {
  var interceptors: Sensory_Api_V1_Video_VideoRecognitionServerInterceptorFactoryProtocol? { get }

  /// Validates the liveness of a single image or stream of images.
  /// Streams a ValidateRecognitionResponse as the images are processed.
  /// Authorization metadata is required {"authorization": "Bearer <TOKEN>"}
  func validateLiveness(context: StreamingResponseCallContext<Sensory_Api_V1_Video_LivenessRecognitionResponse>) -> EventLoopFuture<(StreamEvent<Sensory_Api_V1_Video_ValidateRecognitionRequest>) -> Void>
}

extension Sensory_Api_V1_Video_VideoRecognitionProvider {
  public var serviceName: Substring {
    return Sensory_Api_V1_Video_VideoRecognitionServerMetadata.serviceDescriptor.fullName[...]
  }

  /// Determines, calls and returns the appropriate request handler, depending on the request's method.
  /// Returns nil for methods not handled by this service.
  public func handle(
    method name: Substring,
    context: CallHandlerContext
  ) -> GRPCServerHandlerProtocol? {
    switch name {
    case "ValidateLiveness":
      return BidirectionalStreamingServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Sensory_Api_V1_Video_ValidateRecognitionRequest>(),
        responseSerializer: ProtobufSerializer<Sensory_Api_V1_Video_LivenessRecognitionResponse>(),
        interceptors: self.interceptors?.makeValidateLivenessInterceptors() ?? [],
        observerFactory: self.validateLiveness(context:)
      )

    default:
      return nil
    }
  }
}

#if compiler(>=5.6)

/// Handles all video recognition endpoints
///
/// To implement a server, implement an object which conforms to this protocol.
@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
public protocol Sensory_Api_V1_Video_VideoRecognitionAsyncProvider: CallHandlerProvider {
  static var serviceDescriptor: GRPCServiceDescriptor { get }
  var interceptors: Sensory_Api_V1_Video_VideoRecognitionServerInterceptorFactoryProtocol? { get }

  /// Validates the liveness of a single image or stream of images.
  /// Streams a ValidateRecognitionResponse as the images are processed.
  /// Authorization metadata is required {"authorization": "Bearer <TOKEN>"}
  @Sendable func validateLiveness(
    requestStream: GRPCAsyncRequestStream<Sensory_Api_V1_Video_ValidateRecognitionRequest>,
    responseStream: GRPCAsyncResponseStreamWriter<Sensory_Api_V1_Video_LivenessRecognitionResponse>,
    context: GRPCAsyncServerCallContext
  ) async throws
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Sensory_Api_V1_Video_VideoRecognitionAsyncProvider {
  public static var serviceDescriptor: GRPCServiceDescriptor {
    return Sensory_Api_V1_Video_VideoRecognitionServerMetadata.serviceDescriptor
  }

  public var serviceName: Substring {
    return Sensory_Api_V1_Video_VideoRecognitionServerMetadata.serviceDescriptor.fullName[...]
  }

  public var interceptors: Sensory_Api_V1_Video_VideoRecognitionServerInterceptorFactoryProtocol? {
    return nil
  }

  public func handle(
    method name: Substring,
    context: CallHandlerContext
  ) -> GRPCServerHandlerProtocol? {
    switch name {
    case "ValidateLiveness":
      return GRPCAsyncServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Sensory_Api_V1_Video_ValidateRecognitionRequest>(),
        responseSerializer: ProtobufSerializer<Sensory_Api_V1_Video_LivenessRecognitionResponse>(),
        interceptors: self.interceptors?.makeValidateLivenessInterceptors() ?? [],
        wrapping: self.validateLiveness(requestStream:responseStream:context:)
      )

    default:
      return nil
    }
  }
}

#endif // compiler(>=5.6)

public protocol Sensory_Api_V1_Video_VideoRecognitionServerInterceptorFactoryProtocol {

  /// - Returns: Interceptors to use when handling 'validateLiveness'.
  ///   Defaults to calling `self.makeInterceptors()`.
  func makeValidateLivenessInterceptors() -> [ServerInterceptor<Sensory_Api_V1_Video_ValidateRecognitionRequest, Sensory_Api_V1_Video_LivenessRecognitionResponse>]
}

public enum Sensory_Api_V1_Video_VideoRecognitionServerMetadata {
  public static let serviceDescriptor = GRPCServiceDescriptor(
    name: "VideoRecognition",
    fullName: "sensory.api.v1.video.VideoRecognition",
    methods: [
      Sensory_Api_V1_Video_VideoRecognitionServerMetadata.Methods.validateLiveness,
    ]
  )

  public enum Methods {
    public static let validateLiveness = GRPCMethodDescriptor(
      name: "ValidateLiveness",
      path: "/sensory.api.v1.video.VideoRecognition/ValidateLiveness",
      type: GRPCCallType.bidirectionalStreaming
    )
  }
}
