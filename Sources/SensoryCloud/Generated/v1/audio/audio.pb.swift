// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: v1/audio/audio.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

/// sensory.api.audio

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

public enum Sensory_Api_V1_Audio_AudioPostProcessingAction: SwiftProtobuf.Enum {
  public typealias RawValue = Int

  /// Default value to perform no action
  case notSet // = 0

  /// Request the audio engine to flush its buffers.
  case flush // = 1

  /// Request the audio engine reset itself.
  case reset // = 2

  /// Indicates this message is the final message. The audio engine will create a final result, return it to the client, and close the stream.
  case final // = 3
  case UNRECOGNIZED(Int)

  public init() {
    self = .notSet
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .notSet
    case 1: self = .flush
    case 2: self = .reset
    case 3: self = .final
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .notSet: return 0
    case .flush: return 1
    case .reset: return 2
    case .final: return 3
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Sensory_Api_V1_Audio_AudioPostProcessingAction: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Sensory_Api_V1_Audio_AudioPostProcessingAction] = [
    .notSet,
    .flush,
    .reset,
    .final,
  ]
}

#endif  // swift(>=4.2)

public enum Sensory_Api_V1_Audio_WordState: SwiftProtobuf.Enum {
  public typealias RawValue = Int

  ///Default state is PENDING which indicates that the speech system may decide to change the word in the future given additional audio data
  case pending // = 0

  ///Final state FINAL indicates that the word has moved out of the active logit buffer and can no longer be updated given additional information
  case final // = 1
  case UNRECOGNIZED(Int)

  public init() {
    self = .pending
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .pending
    case 1: self = .final
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .pending: return 0
    case .final: return 1
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Sensory_Api_V1_Audio_WordState: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Sensory_Api_V1_Audio_WordState] = [
    .pending,
    .final,
  ]
}

#endif  // swift(>=4.2)

/// Specifies how sensitive the event threshold of the model should be
public enum Sensory_Api_V1_Audio_ThresholdSensitivity: SwiftProtobuf.Enum {
  public typealias RawValue = Int

  /// Expects about 32 False Accepts per day for Fixed-Trigger models,
  /// and about 10 False Accepts per day for SoundID models
  case lowest // = 0

  /// Expects about 16 False Accepts per day for Fixed-Trigger models,
  /// and about 5 False Accepts per day for SoundID models
  case low // = 1

  /// Expects about 8 False Accepts per day for Fixed-Trigger models,
  /// and about 3 False Accepts per day for SoundID models
  case medium // = 2

  /// Expects about 3 False Accepts per day for Fixed-Trigger models,
  /// and about 2 False Accepts per day for SoundID models
  case high // = 3

  /// Expects about 2 False Accepts per day for Fixed-Trigger models,
  /// and about 1 False Accept per day for SoundID models
  case highest // = 4
  case UNRECOGNIZED(Int)

  public init() {
    self = .lowest
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .lowest
    case 1: self = .low
    case 2: self = .medium
    case 3: self = .high
    case 4: self = .highest
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .lowest: return 0
    case .low: return 1
    case .medium: return 2
    case .high: return 3
    case .highest: return 4
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Sensory_Api_V1_Audio_ThresholdSensitivity: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Sensory_Api_V1_Audio_ThresholdSensitivity] = [
    .lowest,
    .low,
    .medium,
    .high,
    .highest,
  ]
}

#endif  // swift(>=4.2)

/// Request to get a list of the available models
public struct Sensory_Api_V1_Audio_GetModelsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// A model that is available for use
public struct Sensory_Api_V1_Audio_AudioModel {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The name of the model
  public var name: String = String()

  /// Boolean representing if a model can be used in enrollment
  public var isEnrollable: Bool = false

  /// Model type
  public var modelType: Sensory_Api_Common_ModelType = .unknown

  /// Specific phrase used for enrollment (if applicable)
  public var fixedPhrase: String = String()

  /// Required sampling rate for the data
  public var sampleRate: Int32 = 0

  /// List of versions available for this model
  public var versions: [String] = []

  /// The technology backing this model
  public var technology: Sensory_Api_Common_TechnologyType = .notSet

  /// Indicates if liveness is supported by this model
  public var isLivenessSupported: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Action that can be passed along with any audio data. This message instructs the audio engine to
/// perfrom some kind of action after the data is processed.
public struct Sensory_Api_V1_Audio_AudioRequestPostProcessingAction {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// ID that can be set by the client. If a flush or reset is requested,
  /// this ID will be returned to the client upon a successful flush or reset.
  public var actionID: String = String()

  /// The specific action that is being requested.
  public var action: Sensory_Api_V1_Audio_AudioPostProcessingAction = .notSet

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Metadata that can be passed along with any audio response indicating
public struct Sensory_Api_V1_Audio_AudioResponsePostProcessingAction {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// ID that was optionally set by the client with the metadata request.
  public var actionID: String = String()

  /// The specific action that was completed.
  public var action: Sensory_Api_V1_Audio_AudioPostProcessingAction = .notSet

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response containing the models currently available
public struct Sensory_Api_V1_Audio_GetModelsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// List of supported models
  public var models: [Sensory_Api_V1_Audio_AudioModel] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// The top-level message sent by the client for the `CreateEnrollment` method.
/// Multiple `CreateEnrollmentRequest` messages are sent in a stream. The first message
/// must contain a `config` message and must not contain `audioContent`.
/// All subsequent messages must contain `audioContent` and
/// must not contain a `config` message.
public struct Sensory_Api_V1_Audio_CreateEnrollmentRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The streaming request, which is either a config or audio content.
  public var streamingRequest: Sensory_Api_V1_Audio_CreateEnrollmentRequest.OneOf_StreamingRequest? = nil

  /// Provides information that specifies how to process the
  /// request. The first `CreateEnrollmentRequest` message must contain a
  /// `config`  message.
  public var config: Sensory_Api_V1_Audio_CreateEnrollmentConfig {
    get {
      if case .config(let v)? = streamingRequest {return v}
      return Sensory_Api_V1_Audio_CreateEnrollmentConfig()
    }
    set {streamingRequest = .config(newValue)}
  }

  /// The audio data to be recognized. Sequential chunks of audio data are sent
  /// in sequential `CreateEnrollmentRequest` messages. The first
  /// `CreateEnrollmentRequest` message must not contain `audioContent` data
  /// and all subsequent `CreateEnrollmentRequest` messages must contain
  /// `audioContent` data. The audio bytes must be encoded as specified in
  /// `AudioConfig`.
  public var audioContent: Data {
    get {
      if case .audioContent(let v)? = streamingRequest {return v}
      return Data()
    }
    set {streamingRequest = .audioContent(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The streaming request, which is either a config or audio content.
  public enum OneOf_StreamingRequest: Equatable {
    /// Provides information that specifies how to process the
    /// request. The first `CreateEnrollmentRequest` message must contain a
    /// `config`  message.
    case config(Sensory_Api_V1_Audio_CreateEnrollmentConfig)
    /// The audio data to be recognized. Sequential chunks of audio data are sent
    /// in sequential `CreateEnrollmentRequest` messages. The first
    /// `CreateEnrollmentRequest` message must not contain `audioContent` data
    /// and all subsequent `CreateEnrollmentRequest` messages must contain
    /// `audioContent` data. The audio bytes must be encoded as specified in
    /// `AudioConfig`.
    case audioContent(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_CreateEnrollmentRequest.OneOf_StreamingRequest, rhs: Sensory_Api_V1_Audio_CreateEnrollmentRequest.OneOf_StreamingRequest) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.config, .config): return {
        guard case .config(let l) = lhs, case .config(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.audioContent, .audioContent): return {
        guard case .audioContent(let l) = lhs, case .audioContent(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// The top-level message sent by the client for the `Authenticate` method.
/// Multiple `AuthenticateRequest` messages are sent in a stream. The first message
/// must contain a `config` message and must not contain `audioContent`.
/// All subsequent messages must contain `audioContent` and
/// must not contain a `config` message.
public struct Sensory_Api_V1_Audio_AuthenticateRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The streaming request, which is either a config or audio content.
  public var streamingRequest: Sensory_Api_V1_Audio_AuthenticateRequest.OneOf_StreamingRequest? = nil

  /// Provides information that specifies how to process the
  /// request. The first `AuthenticateRequest` message must contain a
  /// `config`  message.
  public var config: Sensory_Api_V1_Audio_AuthenticateConfig {
    get {
      if case .config(let v)? = streamingRequest {return v}
      return Sensory_Api_V1_Audio_AuthenticateConfig()
    }
    set {streamingRequest = .config(newValue)}
  }

  /// The audio data to be recognized. Sequential chunks of audio data are sent
  /// in sequential `AuthenticateRequest` messages. The first
  /// `AuthenticateRequest` message must not contain `audioContent` data
  /// and all subsequent `AuthenticateRequest` messages must contain
  /// `audioContent` data. The audio bytes must be encoded as specified in
  /// `AuthenticateConfig`.
  public var audioContent: Data {
    get {
      if case .audioContent(let v)? = streamingRequest {return v}
      return Data()
    }
    set {streamingRequest = .audioContent(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The streaming request, which is either a config or audio content.
  public enum OneOf_StreamingRequest: Equatable {
    /// Provides information that specifies how to process the
    /// request. The first `AuthenticateRequest` message must contain a
    /// `config`  message.
    case config(Sensory_Api_V1_Audio_AuthenticateConfig)
    /// The audio data to be recognized. Sequential chunks of audio data are sent
    /// in sequential `AuthenticateRequest` messages. The first
    /// `AuthenticateRequest` message must not contain `audioContent` data
    /// and all subsequent `AuthenticateRequest` messages must contain
    /// `audioContent` data. The audio bytes must be encoded as specified in
    /// `AuthenticateConfig`.
    case audioContent(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_AuthenticateRequest.OneOf_StreamingRequest, rhs: Sensory_Api_V1_Audio_AuthenticateRequest.OneOf_StreamingRequest) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.config, .config): return {
        guard case .config(let l) = lhs, case .config(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.audioContent, .audioContent): return {
        guard case .audioContent(let l) = lhs, case .audioContent(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// The top-level message sent by the client for the `ValidateEvent` method.
/// Multiple `ValidateEventRequest` messages are sent in a stream. The first message
/// must contain a `config` message and must not contain `audioContent`.
/// All subsequent messages must contain `audioContent` and
/// must not contain a `config` message.
public struct Sensory_Api_V1_Audio_ValidateEventRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The streaming request, which is either a config or audio content.
  public var streamingRequest: Sensory_Api_V1_Audio_ValidateEventRequest.OneOf_StreamingRequest? = nil

  /// Provides information that specifies how to process the
  /// request. The first `ValidateEventRequest` message must contain a
  /// `config`  message.
  public var config: Sensory_Api_V1_Audio_ValidateEventConfig {
    get {
      if case .config(let v)? = streamingRequest {return v}
      return Sensory_Api_V1_Audio_ValidateEventConfig()
    }
    set {streamingRequest = .config(newValue)}
  }

  /// The audio data to be recognized. Sequential chunks of audio data are sent
  /// in sequential `ValidateEventRequest` messages. The first
  /// `ValidateEventRequest` message must not contain `audioContent` data
  /// and all subsequent `ValidateEventRequest` messages must contain
  /// `audioContent` data. The audio bytes must be encoded as specified in
  /// `ValidateEventConfig`.
  public var audioContent: Data {
    get {
      if case .audioContent(let v)? = streamingRequest {return v}
      return Data()
    }
    set {streamingRequest = .audioContent(newValue)}
  }

  /// Message used to instruct the audio recognition engine to flush or reset.
  public var postProcessingAction: Sensory_Api_V1_Audio_AudioRequestPostProcessingAction {
    get {return _postProcessingAction ?? Sensory_Api_V1_Audio_AudioRequestPostProcessingAction()}
    set {_postProcessingAction = newValue}
  }
  /// Returns true if `postProcessingAction` has been explicitly set.
  public var hasPostProcessingAction: Bool {return self._postProcessingAction != nil}
  /// Clears the value of `postProcessingAction`. Subsequent reads from it will return its default value.
  public mutating func clearPostProcessingAction() {self._postProcessingAction = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The streaming request, which is either a config or audio content.
  public enum OneOf_StreamingRequest: Equatable {
    /// Provides information that specifies how to process the
    /// request. The first `ValidateEventRequest` message must contain a
    /// `config`  message.
    case config(Sensory_Api_V1_Audio_ValidateEventConfig)
    /// The audio data to be recognized. Sequential chunks of audio data are sent
    /// in sequential `ValidateEventRequest` messages. The first
    /// `ValidateEventRequest` message must not contain `audioContent` data
    /// and all subsequent `ValidateEventRequest` messages must contain
    /// `audioContent` data. The audio bytes must be encoded as specified in
    /// `ValidateEventConfig`.
    case audioContent(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_ValidateEventRequest.OneOf_StreamingRequest, rhs: Sensory_Api_V1_Audio_ValidateEventRequest.OneOf_StreamingRequest) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.config, .config): return {
        guard case .config(let l) = lhs, case .config(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.audioContent, .audioContent): return {
        guard case .audioContent(let l) = lhs, case .audioContent(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _postProcessingAction: Sensory_Api_V1_Audio_AudioRequestPostProcessingAction? = nil
}

/// The top-level message sent by the client for the `CreateEnrolledEvent` method.
/// Multiple `CreateEnrolledEventRequest` messages are sent in a stream. The first message
/// must contain a `config` message and must not contain `audioContent`.
/// All subsequent messages must contain `audioContent` and
/// must not contain a `config` message.
public struct Sensory_Api_V1_Audio_CreateEnrolledEventRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The streaming request, which is either a config or audio content.
  public var streamingRequest: Sensory_Api_V1_Audio_CreateEnrolledEventRequest.OneOf_StreamingRequest? = nil

  /// Provides information that specifies how to process the
  /// request. The first `CreateEnrolledEventRequest` message must contain a
  /// `config`  message.
  public var config: Sensory_Api_V1_Audio_CreateEnrollmentEventConfig {
    get {
      if case .config(let v)? = streamingRequest {return v}
      return Sensory_Api_V1_Audio_CreateEnrollmentEventConfig()
    }
    set {streamingRequest = .config(newValue)}
  }

  /// The audio data to be recognized. Sequential chunks of audio data are sent
  /// in sequential `CreateEnrolledEventRequest` messages. The first
  /// `CreateEnrolledEventRequest` message must not contain `audioContent` data
  /// and all subsequent `CreateEnrolledEventRequest` messages must contain
  /// `audioContent` data. The audio bytes must be encoded as specified in
  /// `AudioConfig`.
  public var audioContent: Data {
    get {
      if case .audioContent(let v)? = streamingRequest {return v}
      return Data()
    }
    set {streamingRequest = .audioContent(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The streaming request, which is either a config or audio content.
  public enum OneOf_StreamingRequest: Equatable {
    /// Provides information that specifies how to process the
    /// request. The first `CreateEnrolledEventRequest` message must contain a
    /// `config`  message.
    case config(Sensory_Api_V1_Audio_CreateEnrollmentEventConfig)
    /// The audio data to be recognized. Sequential chunks of audio data are sent
    /// in sequential `CreateEnrolledEventRequest` messages. The first
    /// `CreateEnrolledEventRequest` message must not contain `audioContent` data
    /// and all subsequent `CreateEnrolledEventRequest` messages must contain
    /// `audioContent` data. The audio bytes must be encoded as specified in
    /// `AudioConfig`.
    case audioContent(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_CreateEnrolledEventRequest.OneOf_StreamingRequest, rhs: Sensory_Api_V1_Audio_CreateEnrolledEventRequest.OneOf_StreamingRequest) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.config, .config): return {
        guard case .config(let l) = lhs, case .config(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.audioContent, .audioContent): return {
        guard case .audioContent(let l) = lhs, case .audioContent(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// The top-level message sent by the client for the `ValidateEnrolledEvent` method.
/// Multiple `ValidateEnrolledEventRequest` messages are sent in a stream. The first message
/// must contain a `config` message and must not contain `audioContent`.
/// All subsequent messages must contain `audioContent` and
/// must not contain a `config` message.
public struct Sensory_Api_V1_Audio_ValidateEnrolledEventRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The streaming request, which is either a config or audio content.
  public var streamingRequest: Sensory_Api_V1_Audio_ValidateEnrolledEventRequest.OneOf_StreamingRequest? = nil

  /// Provides information that specifies how to process the
  /// request. The first `ValidateEnrolledEventRequest` message must contain a
  /// `config`  message.
  public var config: Sensory_Api_V1_Audio_ValidateEnrolledEventConfig {
    get {
      if case .config(let v)? = streamingRequest {return v}
      return Sensory_Api_V1_Audio_ValidateEnrolledEventConfig()
    }
    set {streamingRequest = .config(newValue)}
  }

  /// The audio data to be recognized. Sequential chunks of audio data are sent
  /// in sequential `ValidateEnrolledEventRequest` messages. The first
  /// `ValidateEnrolledEventRequest` message must not contain `audioContent` data
  /// and all subsequent `ValidateEnrolledEventRequest` messages must contain
  /// `audioContent` data. The audio bytes must be encoded as specified in
  /// `ValidateEnrolledEventConfig`.
  public var audioContent: Data {
    get {
      if case .audioContent(let v)? = streamingRequest {return v}
      return Data()
    }
    set {streamingRequest = .audioContent(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The streaming request, which is either a config or audio content.
  public enum OneOf_StreamingRequest: Equatable {
    /// Provides information that specifies how to process the
    /// request. The first `ValidateEnrolledEventRequest` message must contain a
    /// `config`  message.
    case config(Sensory_Api_V1_Audio_ValidateEnrolledEventConfig)
    /// The audio data to be recognized. Sequential chunks of audio data are sent
    /// in sequential `ValidateEnrolledEventRequest` messages. The first
    /// `ValidateEnrolledEventRequest` message must not contain `audioContent` data
    /// and all subsequent `ValidateEnrolledEventRequest` messages must contain
    /// `audioContent` data. The audio bytes must be encoded as specified in
    /// `ValidateEnrolledEventConfig`.
    case audioContent(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_ValidateEnrolledEventRequest.OneOf_StreamingRequest, rhs: Sensory_Api_V1_Audio_ValidateEnrolledEventRequest.OneOf_StreamingRequest) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.config, .config): return {
        guard case .config(let l) = lhs, case .config(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.audioContent, .audioContent): return {
        guard case .audioContent(let l) = lhs, case .audioContent(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// The top-level message sent by the client for the `Transcribe` method.
/// Multiple `TranscribeRequest` messages are sent in a stream. The first message
/// must contain a `config` message and must not contain `audioContent`.
/// All subsequent messages must contain `audioContent` and
/// must not contain a `config` message.
public struct Sensory_Api_V1_Audio_TranscribeRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The streaming request, which is either a config or audio content.
  public var streamingRequest: Sensory_Api_V1_Audio_TranscribeRequest.OneOf_StreamingRequest? = nil

  /// Provides information that specifies how to process the
  /// request. The first `TranscribeRequest` message must contain a
  /// `config`  message.
  public var config: Sensory_Api_V1_Audio_TranscribeConfig {
    get {
      if case .config(let v)? = streamingRequest {return v}
      return Sensory_Api_V1_Audio_TranscribeConfig()
    }
    set {streamingRequest = .config(newValue)}
  }

  /// The audio data to be recognized. Sequential chunks of audio data are sent
  /// in sequential `TranscribeRequest` messages. The first
  /// `TranscribeRequest` message must not contain `audioContent` data
  /// and all subsequent `TranscribeRequest` messages must contain
  /// `audioContent` data. The audio bytes must be encoded as specified in
  /// `TranscribeConfig`.
  public var audioContent: Data {
    get {
      if case .audioContent(let v)? = streamingRequest {return v}
      return Data()
    }
    set {streamingRequest = .audioContent(newValue)}
  }

  /// Message used to instruct the audio recognition engine to flush or reset.
  public var postProcessingAction: Sensory_Api_V1_Audio_AudioRequestPostProcessingAction {
    get {return _postProcessingAction ?? Sensory_Api_V1_Audio_AudioRequestPostProcessingAction()}
    set {_postProcessingAction = newValue}
  }
  /// Returns true if `postProcessingAction` has been explicitly set.
  public var hasPostProcessingAction: Bool {return self._postProcessingAction != nil}
  /// Clears the value of `postProcessingAction`. Subsequent reads from it will return its default value.
  public mutating func clearPostProcessingAction() {self._postProcessingAction = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The streaming request, which is either a config or audio content.
  public enum OneOf_StreamingRequest: Equatable {
    /// Provides information that specifies how to process the
    /// request. The first `TranscribeRequest` message must contain a
    /// `config`  message.
    case config(Sensory_Api_V1_Audio_TranscribeConfig)
    /// The audio data to be recognized. Sequential chunks of audio data are sent
    /// in sequential `TranscribeRequest` messages. The first
    /// `TranscribeRequest` message must not contain `audioContent` data
    /// and all subsequent `TranscribeRequest` messages must contain
    /// `audioContent` data. The audio bytes must be encoded as specified in
    /// `TranscribeConfig`.
    case audioContent(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_TranscribeRequest.OneOf_StreamingRequest, rhs: Sensory_Api_V1_Audio_TranscribeRequest.OneOf_StreamingRequest) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.config, .config): return {
        guard case .config(let l) = lhs, case .config(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.audioContent, .audioContent): return {
        guard case .audioContent(let l) = lhs, case .audioContent(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _postProcessingAction: Sensory_Api_V1_Audio_AudioRequestPostProcessingAction? = nil
}

/// The top-level message sent by the client for the `SynthesizeSpeech` method.
public struct Sensory_Api_V1_Audio_SynthesizeSpeechRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The raw text to create voice synthesis for
  public var phrase: String = String()

  /// Configurations for the synthesized voice
  public var config: Sensory_Api_V1_Audio_VoiceSynthesisConfig {
    get {return _config ?? Sensory_Api_V1_Audio_VoiceSynthesisConfig()}
    set {_config = newValue}
  }
  /// Returns true if `config` has been explicitly set.
  public var hasConfig: Bool {return self._config != nil}
  /// Clears the value of `config`. Subsequent reads from it will return its default value.
  public mutating func clearConfig() {self._config = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _config: Sensory_Api_V1_Audio_VoiceSynthesisConfig? = nil
}

/// Response to an enrollment request
public struct Sensory_Api_V1_Audio_CreateEnrollmentResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Percent Complete as values between 0 and 100
  public var percentComplete: Int64 = 0

  /// Relative energy of the processed audio as a value between 0 and 1
  public var audioEnergy: Float = 0

  /// If enrollment is successful, this value will be the unique Enrollment ID
  public var enrollmentID: String = String()

  /// Model used for enrollment
  public var modelName: String = String()

  /// Model version used for enrollment
  public var modelVersion: String = String()

  /// Model prompt instructs the user to say something during enrollment
  public var modelPrompt: String = String()

  /// Percent complete as values between 0 and 100 indicating the progress of the current enrollment segment.
  /// This is relevent in liveness enrollment where multiple groups of numbers must be spoken.
  public var percentSegmentComplete: Int64 = 0

  /// Encrypted enrollment token, this token should be included in authentication requests
  /// If the server is configured to store enrollments server side, this will be left empty
  public var enrollmentToken: Sensory_Api_Common_EnrollmentToken {
    get {return _enrollmentToken ?? Sensory_Api_Common_EnrollmentToken()}
    set {_enrollmentToken = newValue}
  }
  /// Returns true if `enrollmentToken` has been explicitly set.
  public var hasEnrollmentToken: Bool {return self._enrollmentToken != nil}
  /// Clears the value of `enrollmentToken`. Subsequent reads from it will return its default value.
  public mutating func clearEnrollmentToken() {self._enrollmentToken = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _enrollmentToken: Sensory_Api_Common_EnrollmentToken? = nil
}

/// Response to an authentication request
public struct Sensory_Api_V1_Audio_AuthenticateResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Relative energy of the processed audio as a value between 0 and 1
  public var audioEnergy: Float = 0

  /// Success / Failure bit
  public var success: Bool = false

  /// Optional token that will be returned upon a successful authentication if doIncludeToken is set to true in the AuthenticateConfig
  public var token: Sensory_Api_Common_TokenResponse {
    get {return _token ?? Sensory_Api_Common_TokenResponse()}
    set {_token = newValue}
  }
  /// Returns true if `token` has been explicitly set.
  public var hasToken: Bool {return self._token != nil}
  /// Clears the value of `token`. Subsequent reads from it will return its default value.
  public mutating func clearToken() {self._token = nil}

  /// The userID of the authenticated user
  /// Useful when evaluating enrollment groups
  public var userID: String = String()

  /// The enrollmentID of the authenticated enrollment
  /// Useful when evaluating enrollment groups
  public var enrollmentID: String = String()

  /// Model prompt instructs the user to say something during authentication
  public var modelPrompt: String = String()

  /// Percent complete as values between 0 and 100 indicating the progress of the current authentication segment.
  /// This is relevent in liveness enrollment where multiple numbers must be spoken.
  public var percentSegmentComplete: Int64 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _token: Sensory_Api_Common_TokenResponse? = nil
}

/// Response from a ValidateEventRequest
public struct Sensory_Api_V1_Audio_ValidateEventResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Relative energy of the processed audio as a value between 0 and 1
  public var audioEnergy: Float = 0

  /// Success / Failure bit
  public var success: Bool = false

  /// Indicates the id of the particular sound that was recognized.
  /// Useful for combined models where multiple sound events can be recognized by the same model.
  public var resultID: String = String()

  /// The score of the event between -100 to +100. Smaller values typically indicate an invalid sound while larger values would generally indicate a detected sound.
  public var score: Float = 0

  /// If a post processing audio action was requested, this will be populated with the specific
  /// action that was completed along with the actionId optionally set by the client.
  public var postProcessingAction: Sensory_Api_V1_Audio_AudioResponsePostProcessingAction {
    get {return _postProcessingAction ?? Sensory_Api_V1_Audio_AudioResponsePostProcessingAction()}
    set {_postProcessingAction = newValue}
  }
  /// Returns true if `postProcessingAction` has been explicitly set.
  public var hasPostProcessingAction: Bool {return self._postProcessingAction != nil}
  /// Clears the value of `postProcessingAction`. Subsequent reads from it will return its default value.
  public mutating func clearPostProcessingAction() {self._postProcessingAction = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _postProcessingAction: Sensory_Api_V1_Audio_AudioResponsePostProcessingAction? = nil
}

/// Response from a ValidateEventRequest
public struct Sensory_Api_V1_Audio_ValidateEnrolledEventResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Relative energy of the processed audio as a value between 0 and 1
  public var audioEnergy: Float = 0

  /// Success / Failure bit
  public var success: Bool = false

  /// The enrollmentID of the authenticated user
  /// Useful when evaluating enrollment groups
  public var enrollmentID: String = String()

  /// The userID of the authenticated user
  /// Useful when evaluating enrollment groups
  public var userID: String = String()

  /// Model prompt instructs the user to say something during authentication
  public var modelPrompt: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Sensory_Api_V1_Audio_TranscribeWord {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The time in the transcript where the word begins
  public var begintimeMs: UInt64 = 0

  /// The time in the transcript where the word ends
  public var endtimeMs: UInt64 = 0

  /// The confidence score [0.0,1.0] that this word is correctly predicted
  public var confidence: Float = 0

  /// indicates the state of the word with respect to additional updates -- FINAL indicate the word will no longer change
  public var wordState: Sensory_Api_V1_Audio_WordState = .pending

  /// The Positional index within the session where this word appeared
  public var wordIndex: UInt64 = 0

  /// The actual word that was predicted
  public var word: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Word Level Transcription Data
public struct Sensory_Api_V1_Audio_TranscribeWordResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// An array of TranscribeWords
  public var words: [Sensory_Api_V1_Audio_TranscribeWord] = []

  /// Lowest index of the words in wordList
  public var firstWordIndex: UInt64 = 0

  /// Highest index of the words in wordList
  public var lastWordIndex: UInt64 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response from a TranscribeRequest
public struct Sensory_Api_V1_Audio_TranscribeResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Relative energy of the processed audio as a value between 0 and 1
  public var audioEnergy: Float = 0

  /// Text of the current transcript, sliding window on ~7 seconds
  public var transcript: String = String()

  /// Indicates if the returned transcript is an intermediate result
  public var isPartialResult: Bool = false

  /// A response including word metadata
  public var wordList: Sensory_Api_V1_Audio_TranscribeWordResponse {
    get {return _wordList ?? Sensory_Api_V1_Audio_TranscribeWordResponse()}
    set {_wordList = newValue}
  }
  /// Returns true if `wordList` has been explicitly set.
  public var hasWordList: Bool {return self._wordList != nil}
  /// Clears the value of `wordList`. Subsequent reads from it will return its default value.
  public mutating func clearWordList() {self._wordList = nil}

  /// If a post processing audio action was requested, this will be populated with the specific
  /// action that was completed along with the actionId optionally set by the client.
  public var postProcessingAction: Sensory_Api_V1_Audio_AudioResponsePostProcessingAction {
    get {return _postProcessingAction ?? Sensory_Api_V1_Audio_AudioResponsePostProcessingAction()}
    set {_postProcessingAction = newValue}
  }
  /// Returns true if `postProcessingAction` has been explicitly set.
  public var hasPostProcessingAction: Bool {return self._postProcessingAction != nil}
  /// Clears the value of `postProcessingAction`. Subsequent reads from it will return its default value.
  public mutating func clearPostProcessingAction() {self._postProcessingAction = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _wordList: Sensory_Api_V1_Audio_TranscribeWordResponse? = nil
  fileprivate var _postProcessingAction: Sensory_Api_V1_Audio_AudioResponsePostProcessingAction? = nil
}

/// The response to a speech synthesis request
public struct Sensory_Api_V1_Audio_SynthesizeSpeechResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var streamingResponse: Sensory_Api_V1_Audio_SynthesizeSpeechResponse.OneOf_StreamingResponse? = nil

  /// Provides information that specifies how the audio has been formatted.
  /// The first `SpeechSynthesisResponse` message will contain a `config` message.
  public var config: Sensory_Api_V1_Audio_AudioConfig {
    get {
      if case .config(let v)? = streamingResponse {return v}
      return Sensory_Api_V1_Audio_AudioConfig()
    }
    set {streamingResponse = .config(newValue)}
  }

  /// The synthesized audio data. Sequential chunks of audio data are sent in
  /// sequential `SpeechSynthesisResponse` messages. The first `SpeechSynthesisResponse`
  /// message will only contain `config` data and all supsequent `SpeechSynthesisResponse`
  /// messages will contain `audioContent` data.
  public var audioContent: Data {
    get {
      if case .audioContent(let v)? = streamingResponse {return v}
      return Data()
    }
    set {streamingResponse = .audioContent(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public enum OneOf_StreamingResponse: Equatable {
    /// Provides information that specifies how the audio has been formatted.
    /// The first `SpeechSynthesisResponse` message will contain a `config` message.
    case config(Sensory_Api_V1_Audio_AudioConfig)
    /// The synthesized audio data. Sequential chunks of audio data are sent in
    /// sequential `SpeechSynthesisResponse` messages. The first `SpeechSynthesisResponse`
    /// message will only contain `config` data and all supsequent `SpeechSynthesisResponse`
    /// messages will contain `audioContent` data.
    case audioContent(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_SynthesizeSpeechResponse.OneOf_StreamingResponse, rhs: Sensory_Api_V1_Audio_SynthesizeSpeechResponse.OneOf_StreamingResponse) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.config, .config): return {
        guard case .config(let l) = lhs, case .config(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.audioContent, .audioContent): return {
        guard case .audioContent(let l) = lhs, case .audioContent(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// Provides information for an audio-based enrollment
public struct Sensory_Api_V1_Audio_CreateEnrollmentConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Provides information that specifies how to
  /// process the request.
  public var audio: Sensory_Api_V1_Audio_AudioConfig {
    get {return _audio ?? Sensory_Api_V1_Audio_AudioConfig()}
    set {_audio = newValue}
  }
  /// Returns true if `audio` has been explicitly set.
  public var hasAudio: Bool {return self._audio != nil}
  /// Clears the value of `audio`. Subsequent reads from it will return its default value.
  public mutating func clearAudio() {self._audio = nil}

  /// The unique user Identifer. This value should be a unique email address or username known by the user.
  public var userID: String = String()

  /// The unique device Identifer. This value should be something retrieved by the devie prior to enrollment (like MAC Address)
  /// this value is used to identify a device uniquely across multiple enrollments
  public var deviceID: String = String()

  /// Name of background model to be enrolled in
  /// Background models can be retrieved from the GetModels() gRPC call
  public var modelName: String = String()

  /// Description of the enrollment as entered by the user.
  /// Max length is 1023 characters
  public var description_p: String = String()

  /// Enable liveness if supported by the audio model
  public var isLivenessEnabled: Bool = false

  /// Optional: Controls the allowed length of enrollment. Longer enrollments are generally more accurate, but take more time to perform.
  /// For text-independent enrollments, enrollmentDuration may be set. For any other enrollment, enrollmentNumUtterances may be set.
  public var enrollLength: Sensory_Api_V1_Audio_CreateEnrollmentConfig.OneOf_EnrollLength? = nil

  /// The number of times a specific phrase should be uttered during an enrollment.
  /// The default value is 4.
  public var enrollmentNumUtterances: UInt32 {
    get {
      if case .enrollmentNumUtterances(let v)? = enrollLength {return v}
      return 0
    }
    set {enrollLength = .enrollmentNumUtterances(newValue)}
  }

  /// The allowed length of text-independent enrollments (such as digit liveness)
  /// The default value is 12.5 seconds without liveness and 8 seconds with liveness.
  public var enrollmentDuration: Float {
    get {
      if case .enrollmentDuration(let v)? = enrollLength {return v}
      return 0
    }
    set {enrollLength = .enrollmentDuration(newValue)}
  }

  /// Reference Id allows clients to assign their own identifier to enrollments for various purposes
  /// such as tying an audio and video enrollment together.
  public var referenceID: String = String()

  /// Prevent the server from storing the enrollment template. The template will be returned to the client for storage.
  public var disableServerEnrollmentTemplateStorage: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Optional: Controls the allowed length of enrollment. Longer enrollments are generally more accurate, but take more time to perform.
  /// For text-independent enrollments, enrollmentDuration may be set. For any other enrollment, enrollmentNumUtterances may be set.
  public enum OneOf_EnrollLength: Equatable {
    /// The number of times a specific phrase should be uttered during an enrollment.
    /// The default value is 4.
    case enrollmentNumUtterances(UInt32)
    /// The allowed length of text-independent enrollments (such as digit liveness)
    /// The default value is 12.5 seconds without liveness and 8 seconds with liveness.
    case enrollmentDuration(Float)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_CreateEnrollmentConfig.OneOf_EnrollLength, rhs: Sensory_Api_V1_Audio_CreateEnrollmentConfig.OneOf_EnrollLength) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.enrollmentNumUtterances, .enrollmentNumUtterances): return {
        guard case .enrollmentNumUtterances(let l) = lhs, case .enrollmentNumUtterances(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.enrollmentDuration, .enrollmentDuration): return {
        guard case .enrollmentDuration(let l) = lhs, case .enrollmentDuration(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _audio: Sensory_Api_V1_Audio_AudioConfig? = nil
}

/// Provides information for an audio-based authentication
public struct Sensory_Api_V1_Audio_AuthenticateConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Provides information that specifies how to
  /// process the request.
  public var audio: Sensory_Api_V1_Audio_AudioConfig {
    get {return _audio ?? Sensory_Api_V1_Audio_AudioConfig()}
    set {_audio = newValue}
  }
  /// Returns true if `audio` has been explicitly set.
  public var hasAudio: Bool {return self._audio != nil}
  /// Clears the value of `audio`. Subsequent reads from it will return its default value.
  public mutating func clearAudio() {self._audio = nil}

  /// An identifier for what to authenticate against, either an individual enrollment or a group of enrollments
  public var authID: Sensory_Api_V1_Audio_AuthenticateConfig.OneOf_AuthID? = nil

  /// Unique identifier created at enrollment
  public var enrollmentID: String {
    get {
      if case .enrollmentID(let v)? = authID {return v}
      return String()
    }
    set {authID = .enrollmentID(newValue)}
  }

  /// Unique identifier for an enrollment group
  public var enrollmentGroupID: String {
    get {
      if case .enrollmentGroupID(let v)? = authID {return v}
      return String()
    }
    set {authID = .enrollmentGroupID(newValue)}
  }

  /// A boolean indicating if the response should include an OAuth token for the user associated with the enrollmentId
  /// The OAuth token will only be returned if the authentication is successful.
  /// It's important to note there will be a minor performance hit to authentication, as OAuth token generation is a semi-expensive operation.
  public var doIncludeToken: Bool = false

  /// The model sensitivity
  public var sensitivity: Sensory_Api_V1_Audio_ThresholdSensitivity = .lowest

  /// The model security
  public var security: Sensory_Api_V1_Audio_AuthenticateConfig.ThresholdSecurity = .high

  /// Enable liveness if supported by the audio model
  public var isLivenessEnabled: Bool = false

  /// Encrypted enrollment token that was provided on enrollment creation
  /// If the server is configured to store enrollments server side, this may be left blank
  public var enrollmentToken: Data = Data()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// An identifier for what to authenticate against, either an individual enrollment or a group of enrollments
  public enum OneOf_AuthID: Equatable {
    /// Unique identifier created at enrollment
    case enrollmentID(String)
    /// Unique identifier for an enrollment group
    case enrollmentGroupID(String)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_AuthenticateConfig.OneOf_AuthID, rhs: Sensory_Api_V1_Audio_AuthenticateConfig.OneOf_AuthID) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.enrollmentID, .enrollmentID): return {
        guard case .enrollmentID(let l) = lhs, case .enrollmentID(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.enrollmentGroupID, .enrollmentGroupID): return {
        guard case .enrollmentGroupID(let l) = lhs, case .enrollmentGroupID(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  /// Specifies the authentication security mode
  public enum ThresholdSecurity: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// Default  Setting.  Targets  low  Imposter  Accept  (IA).  Recommended  when  TSSV  is  used  solely  for
    /// biometric authentication. Generally this mode assumes the user will produce the voice password in
    /// isolation (rather than part of a voice-query) and over short listening windows (e.g., 7 seconds or
    /// less).  This  provides  the  ultimate  rejection  of  imposter  voices  at  the  expense  of  false-rejects,
    /// particularly in high-noise environments 5 dB SNR and below.
    case high // = 0

    /// Targets low False Reject (FR). Recommended to achieve low false reject or for applications where
    /// errors in imposter accept are not considered severe. Provides reduced rejection in extremely noisy
    /// environments. This mode is typically selected when TSSV is used in conjunction with a front-end
    /// fixed-trigger or part of a combined solution for voice-triggering in which the goal may be to gently
    /// reduce  voice-trigger  false  accepts  in  the  presence  of  noise,  or  to  reduce  the  chances  that  non-
    /// enrollees who say the wake word might accidentally cause an always-listening device to false-fire.
    case low // = 1
    case UNRECOGNIZED(Int)

    public init() {
      self = .high
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .high
      case 1: self = .low
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .high: return 0
      case .low: return 1
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}

  fileprivate var _audio: Sensory_Api_V1_Audio_AudioConfig? = nil
}

#if swift(>=4.2)

extension Sensory_Api_V1_Audio_AuthenticateConfig.ThresholdSecurity: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Sensory_Api_V1_Audio_AuthenticateConfig.ThresholdSecurity] = [
    .high,
    .low,
  ]
}

#endif  // swift(>=4.2)

/// Provides information for an audio-based event recognition
public struct Sensory_Api_V1_Audio_ValidateEventConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Provides information that specifies how to
  /// process the request.
  public var audio: Sensory_Api_V1_Audio_AudioConfig {
    get {return _audio ?? Sensory_Api_V1_Audio_AudioConfig()}
    set {_audio = newValue}
  }
  /// Returns true if `audio` has been explicitly set.
  public var hasAudio: Bool {return self._audio != nil}
  /// Clears the value of `audio`. Subsequent reads from it will return its default value.
  public mutating func clearAudio() {self._audio = nil}

  /// Name of model to validate against
  /// Models can be retrieved from the GetModels() gRPC call
  public var modelName: String = String()

  /// The unique user Identifer
  public var userID: String = String()

  /// The model sensitivity
  public var sensitivity: Sensory_Api_V1_Audio_ThresholdSensitivity = .lowest

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _audio: Sensory_Api_V1_Audio_AudioConfig? = nil
}

public struct Sensory_Api_V1_Audio_CreateEnrollmentEventConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Provides information that specifies how to
  /// process the request.
  public var audio: Sensory_Api_V1_Audio_AudioConfig {
    get {return _audio ?? Sensory_Api_V1_Audio_AudioConfig()}
    set {_audio = newValue}
  }
  /// Returns true if `audio` has been explicitly set.
  public var hasAudio: Bool {return self._audio != nil}
  /// Clears the value of `audio`. Subsequent reads from it will return its default value.
  public mutating func clearAudio() {self._audio = nil}

  /// The unique user Identifer. This value should be a unique email address or username known by the user.
  public var userID: String = String()

  /// Name of background model to be enrolled in
  /// Background models can be retrieved from the GetModels() gRPC call
  public var modelName: String = String()

  /// Description of the enrollment as entered by the user.
  /// Max length is 1023 characters
  public var description_p: String = String()

  /// Optional: Controls the allowed length of enrollment. Longer enrollments are generally more accurate, but take more time to perform.
  /// For text-independent enrollments, enrollmentDuration may be set. For any other enrollment, enrollmentNumUtterances may be set.
  public var enrollLength: Sensory_Api_V1_Audio_CreateEnrollmentEventConfig.OneOf_EnrollLength? = nil

  /// The number of times a specific phrase should be uttered during an enrollment.
  /// The default value is 4.
  public var enrollmentNumUtterances: UInt32 {
    get {
      if case .enrollmentNumUtterances(let v)? = enrollLength {return v}
      return 0
    }
    set {enrollLength = .enrollmentNumUtterances(newValue)}
  }

  /// The allowed length of text-independent enrollments (such as digit liveness)
  /// The default value is 12.5 seconds without liveness and 8 seconds with liveness.
  public var enrollmentDuration: Float {
    get {
      if case .enrollmentDuration(let v)? = enrollLength {return v}
      return 0
    }
    set {enrollLength = .enrollmentDuration(newValue)}
  }

  /// Reference Id allows clients to assign their own identifier to enrollments for various purposes
  /// such as tying an audio and video enrollment together.
  public var referenceID: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Optional: Controls the allowed length of enrollment. Longer enrollments are generally more accurate, but take more time to perform.
  /// For text-independent enrollments, enrollmentDuration may be set. For any other enrollment, enrollmentNumUtterances may be set.
  public enum OneOf_EnrollLength: Equatable {
    /// The number of times a specific phrase should be uttered during an enrollment.
    /// The default value is 4.
    case enrollmentNumUtterances(UInt32)
    /// The allowed length of text-independent enrollments (such as digit liveness)
    /// The default value is 12.5 seconds without liveness and 8 seconds with liveness.
    case enrollmentDuration(Float)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_CreateEnrollmentEventConfig.OneOf_EnrollLength, rhs: Sensory_Api_V1_Audio_CreateEnrollmentEventConfig.OneOf_EnrollLength) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.enrollmentNumUtterances, .enrollmentNumUtterances): return {
        guard case .enrollmentNumUtterances(let l) = lhs, case .enrollmentNumUtterances(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.enrollmentDuration, .enrollmentDuration): return {
        guard case .enrollmentDuration(let l) = lhs, case .enrollmentDuration(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _audio: Sensory_Api_V1_Audio_AudioConfig? = nil
}

/// Provides information for an audio-based event validation
public struct Sensory_Api_V1_Audio_ValidateEnrolledEventConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Provides information that specifies how to
  /// process the request.
  public var audio: Sensory_Api_V1_Audio_AudioConfig {
    get {return _audio ?? Sensory_Api_V1_Audio_AudioConfig()}
    set {_audio = newValue}
  }
  /// Returns true if `audio` has been explicitly set.
  public var hasAudio: Bool {return self._audio != nil}
  /// Clears the value of `audio`. Subsequent reads from it will return its default value.
  public mutating func clearAudio() {self._audio = nil}

  /// An identifier for what to authenticate against, either an individual enrollment or a group of enrollments
  public var authID: Sensory_Api_V1_Audio_ValidateEnrolledEventConfig.OneOf_AuthID? = nil

  /// Unique identifier created at enrollment
  public var enrollmentID: String {
    get {
      if case .enrollmentID(let v)? = authID {return v}
      return String()
    }
    set {authID = .enrollmentID(newValue)}
  }

  /// Unique identifier for an enrollment group
  public var enrollmentGroupID: String {
    get {
      if case .enrollmentGroupID(let v)? = authID {return v}
      return String()
    }
    set {authID = .enrollmentGroupID(newValue)}
  }

  /// The model sensitivity
  public var sensitivity: Sensory_Api_V1_Audio_ThresholdSensitivity = .lowest

  /// Encrypted enrollment token that was provided on enrollment creation
  /// If the server is configured to store enrollments server side, this may be left blank
  public var enrollmentToken: Data = Data()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// An identifier for what to authenticate against, either an individual enrollment or a group of enrollments
  public enum OneOf_AuthID: Equatable {
    /// Unique identifier created at enrollment
    case enrollmentID(String)
    /// Unique identifier for an enrollment group
    case enrollmentGroupID(String)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_ValidateEnrolledEventConfig.OneOf_AuthID, rhs: Sensory_Api_V1_Audio_ValidateEnrolledEventConfig.OneOf_AuthID) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.enrollmentID, .enrollmentID): return {
        guard case .enrollmentID(let l) = lhs, case .enrollmentID(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.enrollmentGroupID, .enrollmentGroupID): return {
        guard case .enrollmentGroupID(let l) = lhs, case .enrollmentGroupID(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _audio: Sensory_Api_V1_Audio_AudioConfig? = nil
}

/// Provides information for an audio-based transcription
public struct Sensory_Api_V1_Audio_TranscribeConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Provides information that specifies how to
  /// process the request.
  public var audio: Sensory_Api_V1_Audio_AudioConfig {
    get {return _audio ?? Sensory_Api_V1_Audio_AudioConfig()}
    set {_audio = newValue}
  }
  /// Returns true if `audio` has been explicitly set.
  public var hasAudio: Bool {return self._audio != nil}
  /// Clears the value of `audio`. Subsequent reads from it will return its default value.
  public mutating func clearAudio() {self._audio = nil}

  /// Name of model to validate against
  /// Models can be retrieved from the GetModels() gRPC call
  public var modelName: String = String()

  /// The unique user Identifer
  public var userID: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _audio: Sensory_Api_V1_Audio_AudioConfig? = nil
}

/// Provides audio configuration information that specifies how to process the request.
public struct Sensory_Api_V1_Audio_AudioConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Encoding of all sent audio data.
  public var encoding: Sensory_Api_V1_Audio_AudioConfig.AudioEncoding = .linear16

  /// Sample rate in Hertz of the audio data sent in all messages. 16000Hz is optimal.
  public var sampleRateHertz: Int32 = 0

  /// The number of channels in the input audio data.
  public var audioChannelCount: Int32 = 0

  /// Required. The language of the supplied audio as a
  /// [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
  /// Example: "en-US".
  public var languageCode: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The encoding of the audio data sent in the request.
  public enum AudioEncoding: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
    case linear16 // = 0

    /// `FLAC` (Free Lossless Audio
    /// Codec) is the recommended encoding because it is
    /// lossless--therefore recognition is not compromised--and
    /// requires only about half the bandwidth of `LINEAR16`.
    case flac // = 1

    /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
    case mulaw // = 2
    case UNRECOGNIZED(Int)

    public init() {
      self = .linear16
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .linear16
      case 1: self = .flac
      case 2: self = .mulaw
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .linear16: return 0
      case .flac: return 1
      case .mulaw: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}
}

#if swift(>=4.2)

extension Sensory_Api_V1_Audio_AudioConfig.AudioEncoding: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Sensory_Api_V1_Audio_AudioConfig.AudioEncoding] = [
    .linear16,
    .flac,
    .mulaw,
  ]
}

#endif  // swift(>=4.2)

/// Configurations for the voice synthesis model
public struct Sensory_Api_V1_Audio_VoiceSynthesisConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Provides information that specifies how the synthesized audio should be formatted
  public var audio: Sensory_Api_V1_Audio_AudioConfig {
    get {return _audio ?? Sensory_Api_V1_Audio_AudioConfig()}
    set {_audio = newValue}
  }
  /// Returns true if `audio` has been explicitly set.
  public var hasAudio: Bool {return self._audio != nil}
  /// Clears the value of `audio`. Subsequent reads from it will return its default value.
  public mutating func clearAudio() {self._audio = nil}

  /// Required. The name of the voice to use for voice synthesis
  public var voice: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _audio: Sensory_Api_V1_Audio_AudioConfig? = nil
}

#if swift(>=5.5) && canImport(_Concurrency)
extension Sensory_Api_V1_Audio_AudioPostProcessingAction: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_WordState: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_ThresholdSensitivity: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_GetModelsRequest: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_AudioModel: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_AudioRequestPostProcessingAction: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_AudioResponsePostProcessingAction: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_GetModelsResponse: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_CreateEnrollmentRequest: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_CreateEnrollmentRequest.OneOf_StreamingRequest: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_AuthenticateRequest: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_AuthenticateRequest.OneOf_StreamingRequest: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_ValidateEventRequest: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_ValidateEventRequest.OneOf_StreamingRequest: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_CreateEnrolledEventRequest: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_CreateEnrolledEventRequest.OneOf_StreamingRequest: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_ValidateEnrolledEventRequest: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_ValidateEnrolledEventRequest.OneOf_StreamingRequest: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_TranscribeRequest: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_TranscribeRequest.OneOf_StreamingRequest: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_SynthesizeSpeechRequest: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_CreateEnrollmentResponse: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_AuthenticateResponse: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_ValidateEventResponse: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_ValidateEnrolledEventResponse: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_TranscribeWord: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_TranscribeWordResponse: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_TranscribeResponse: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_SynthesizeSpeechResponse: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_SynthesizeSpeechResponse.OneOf_StreamingResponse: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_CreateEnrollmentConfig: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_CreateEnrollmentConfig.OneOf_EnrollLength: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_AuthenticateConfig: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_AuthenticateConfig.OneOf_AuthID: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_AuthenticateConfig.ThresholdSecurity: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_ValidateEventConfig: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_CreateEnrollmentEventConfig: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_CreateEnrollmentEventConfig.OneOf_EnrollLength: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_ValidateEnrolledEventConfig: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_ValidateEnrolledEventConfig.OneOf_AuthID: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_TranscribeConfig: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_AudioConfig: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_AudioConfig.AudioEncoding: @unchecked Sendable {}
extension Sensory_Api_V1_Audio_VoiceSynthesisConfig: @unchecked Sendable {}
#endif  // swift(>=5.5) && canImport(_Concurrency)

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "sensory.api.v1.audio"

extension Sensory_Api_V1_Audio_AudioPostProcessingAction: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "NOT_SET"),
    1: .same(proto: "FLUSH"),
    2: .same(proto: "RESET"),
    3: .same(proto: "FINAL"),
  ]
}

extension Sensory_Api_V1_Audio_WordState: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "WORDSTATE_PENDING"),
    1: .same(proto: "WORDSTATE_FINAL"),
  ]
}

extension Sensory_Api_V1_Audio_ThresholdSensitivity: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "LOWEST"),
    1: .same(proto: "LOW"),
    2: .same(proto: "MEDIUM"),
    3: .same(proto: "HIGH"),
    4: .same(proto: "HIGHEST"),
  ]
}

extension Sensory_Api_V1_Audio_GetModelsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GetModelsRequest"
  public static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let _ = try decoder.nextFieldNumber() {
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_GetModelsRequest, rhs: Sensory_Api_V1_Audio_GetModelsRequest) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AudioModel: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AudioModel"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .same(proto: "isEnrollable"),
    3: .same(proto: "modelType"),
    4: .same(proto: "fixedPhrase"),
    5: .same(proto: "sampleRate"),
    6: .same(proto: "versions"),
    7: .same(proto: "technology"),
    8: .same(proto: "isLivenessSupported"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.isEnrollable) }()
      case 3: try { try decoder.decodeSingularEnumField(value: &self.modelType) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.fixedPhrase) }()
      case 5: try { try decoder.decodeSingularInt32Field(value: &self.sampleRate) }()
      case 6: try { try decoder.decodeRepeatedStringField(value: &self.versions) }()
      case 7: try { try decoder.decodeSingularEnumField(value: &self.technology) }()
      case 8: try { try decoder.decodeSingularBoolField(value: &self.isLivenessSupported) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if self.isEnrollable != false {
      try visitor.visitSingularBoolField(value: self.isEnrollable, fieldNumber: 2)
    }
    if self.modelType != .unknown {
      try visitor.visitSingularEnumField(value: self.modelType, fieldNumber: 3)
    }
    if !self.fixedPhrase.isEmpty {
      try visitor.visitSingularStringField(value: self.fixedPhrase, fieldNumber: 4)
    }
    if self.sampleRate != 0 {
      try visitor.visitSingularInt32Field(value: self.sampleRate, fieldNumber: 5)
    }
    if !self.versions.isEmpty {
      try visitor.visitRepeatedStringField(value: self.versions, fieldNumber: 6)
    }
    if self.technology != .notSet {
      try visitor.visitSingularEnumField(value: self.technology, fieldNumber: 7)
    }
    if self.isLivenessSupported != false {
      try visitor.visitSingularBoolField(value: self.isLivenessSupported, fieldNumber: 8)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_AudioModel, rhs: Sensory_Api_V1_Audio_AudioModel) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.isEnrollable != rhs.isEnrollable {return false}
    if lhs.modelType != rhs.modelType {return false}
    if lhs.fixedPhrase != rhs.fixedPhrase {return false}
    if lhs.sampleRate != rhs.sampleRate {return false}
    if lhs.versions != rhs.versions {return false}
    if lhs.technology != rhs.technology {return false}
    if lhs.isLivenessSupported != rhs.isLivenessSupported {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AudioRequestPostProcessingAction: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AudioRequestPostProcessingAction"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "actionId"),
    2: .same(proto: "action"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.actionID) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.action) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.actionID.isEmpty {
      try visitor.visitSingularStringField(value: self.actionID, fieldNumber: 1)
    }
    if self.action != .notSet {
      try visitor.visitSingularEnumField(value: self.action, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_AudioRequestPostProcessingAction, rhs: Sensory_Api_V1_Audio_AudioRequestPostProcessingAction) -> Bool {
    if lhs.actionID != rhs.actionID {return false}
    if lhs.action != rhs.action {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AudioResponsePostProcessingAction: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AudioResponsePostProcessingAction"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "actionId"),
    2: .same(proto: "action"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.actionID) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.action) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.actionID.isEmpty {
      try visitor.visitSingularStringField(value: self.actionID, fieldNumber: 1)
    }
    if self.action != .notSet {
      try visitor.visitSingularEnumField(value: self.action, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_AudioResponsePostProcessingAction, rhs: Sensory_Api_V1_Audio_AudioResponsePostProcessingAction) -> Bool {
    if lhs.actionID != rhs.actionID {return false}
    if lhs.action != rhs.action {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_GetModelsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GetModelsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "models"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.models) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.models.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.models, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_GetModelsResponse, rhs: Sensory_Api_V1_Audio_GetModelsResponse) -> Bool {
    if lhs.models != rhs.models {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_CreateEnrollmentRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateEnrollmentRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .same(proto: "audioContent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Sensory_Api_V1_Audio_CreateEnrollmentConfig?
        var hadOneofValue = false
        if let current = self.streamingRequest {
          hadOneofValue = true
          if case .config(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .config(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingRequest != nil {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .audioContent(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.streamingRequest {
    case .config?: try {
      guard case .config(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .audioContent?: try {
      guard case .audioContent(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_CreateEnrollmentRequest, rhs: Sensory_Api_V1_Audio_CreateEnrollmentRequest) -> Bool {
    if lhs.streamingRequest != rhs.streamingRequest {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AuthenticateRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AuthenticateRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .same(proto: "audioContent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Sensory_Api_V1_Audio_AuthenticateConfig?
        var hadOneofValue = false
        if let current = self.streamingRequest {
          hadOneofValue = true
          if case .config(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .config(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingRequest != nil {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .audioContent(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.streamingRequest {
    case .config?: try {
      guard case .config(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .audioContent?: try {
      guard case .audioContent(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_AuthenticateRequest, rhs: Sensory_Api_V1_Audio_AuthenticateRequest) -> Bool {
    if lhs.streamingRequest != rhs.streamingRequest {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_ValidateEventRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ValidateEventRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .same(proto: "audioContent"),
    10: .same(proto: "postProcessingAction"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Sensory_Api_V1_Audio_ValidateEventConfig?
        var hadOneofValue = false
        if let current = self.streamingRequest {
          hadOneofValue = true
          if case .config(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .config(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingRequest != nil {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .audioContent(v)
        }
      }()
      case 10: try { try decoder.decodeSingularMessageField(value: &self._postProcessingAction) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.streamingRequest {
    case .config?: try {
      guard case .config(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .audioContent?: try {
      guard case .audioContent(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try { if let v = self._postProcessingAction {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_ValidateEventRequest, rhs: Sensory_Api_V1_Audio_ValidateEventRequest) -> Bool {
    if lhs.streamingRequest != rhs.streamingRequest {return false}
    if lhs._postProcessingAction != rhs._postProcessingAction {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_CreateEnrolledEventRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateEnrolledEventRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .same(proto: "audioContent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Sensory_Api_V1_Audio_CreateEnrollmentEventConfig?
        var hadOneofValue = false
        if let current = self.streamingRequest {
          hadOneofValue = true
          if case .config(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .config(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingRequest != nil {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .audioContent(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.streamingRequest {
    case .config?: try {
      guard case .config(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .audioContent?: try {
      guard case .audioContent(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_CreateEnrolledEventRequest, rhs: Sensory_Api_V1_Audio_CreateEnrolledEventRequest) -> Bool {
    if lhs.streamingRequest != rhs.streamingRequest {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_ValidateEnrolledEventRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ValidateEnrolledEventRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .same(proto: "audioContent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Sensory_Api_V1_Audio_ValidateEnrolledEventConfig?
        var hadOneofValue = false
        if let current = self.streamingRequest {
          hadOneofValue = true
          if case .config(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .config(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingRequest != nil {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .audioContent(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.streamingRequest {
    case .config?: try {
      guard case .config(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .audioContent?: try {
      guard case .audioContent(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_ValidateEnrolledEventRequest, rhs: Sensory_Api_V1_Audio_ValidateEnrolledEventRequest) -> Bool {
    if lhs.streamingRequest != rhs.streamingRequest {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_TranscribeRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TranscribeRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .same(proto: "audioContent"),
    10: .same(proto: "postProcessingAction"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Sensory_Api_V1_Audio_TranscribeConfig?
        var hadOneofValue = false
        if let current = self.streamingRequest {
          hadOneofValue = true
          if case .config(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .config(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingRequest != nil {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .audioContent(v)
        }
      }()
      case 10: try { try decoder.decodeSingularMessageField(value: &self._postProcessingAction) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.streamingRequest {
    case .config?: try {
      guard case .config(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .audioContent?: try {
      guard case .audioContent(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try { if let v = self._postProcessingAction {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_TranscribeRequest, rhs: Sensory_Api_V1_Audio_TranscribeRequest) -> Bool {
    if lhs.streamingRequest != rhs.streamingRequest {return false}
    if lhs._postProcessingAction != rhs._postProcessingAction {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_SynthesizeSpeechRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SynthesizeSpeechRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "phrase"),
    2: .same(proto: "config"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.phrase) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._config) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.phrase.isEmpty {
      try visitor.visitSingularStringField(value: self.phrase, fieldNumber: 1)
    }
    try { if let v = self._config {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_SynthesizeSpeechRequest, rhs: Sensory_Api_V1_Audio_SynthesizeSpeechRequest) -> Bool {
    if lhs.phrase != rhs.phrase {return false}
    if lhs._config != rhs._config {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_CreateEnrollmentResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateEnrollmentResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "percentComplete"),
    2: .same(proto: "audioEnergy"),
    3: .same(proto: "enrollmentId"),
    4: .same(proto: "modelName"),
    5: .same(proto: "modelVersion"),
    6: .same(proto: "modelPrompt"),
    7: .same(proto: "percentSegmentComplete"),
    8: .same(proto: "enrollmentToken"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.percentComplete) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.audioEnergy) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.enrollmentID) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.modelName) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.modelVersion) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.modelPrompt) }()
      case 7: try { try decoder.decodeSingularInt64Field(value: &self.percentSegmentComplete) }()
      case 8: try { try decoder.decodeSingularMessageField(value: &self._enrollmentToken) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.percentComplete != 0 {
      try visitor.visitSingularInt64Field(value: self.percentComplete, fieldNumber: 1)
    }
    if self.audioEnergy != 0 {
      try visitor.visitSingularFloatField(value: self.audioEnergy, fieldNumber: 2)
    }
    if !self.enrollmentID.isEmpty {
      try visitor.visitSingularStringField(value: self.enrollmentID, fieldNumber: 3)
    }
    if !self.modelName.isEmpty {
      try visitor.visitSingularStringField(value: self.modelName, fieldNumber: 4)
    }
    if !self.modelVersion.isEmpty {
      try visitor.visitSingularStringField(value: self.modelVersion, fieldNumber: 5)
    }
    if !self.modelPrompt.isEmpty {
      try visitor.visitSingularStringField(value: self.modelPrompt, fieldNumber: 6)
    }
    if self.percentSegmentComplete != 0 {
      try visitor.visitSingularInt64Field(value: self.percentSegmentComplete, fieldNumber: 7)
    }
    try { if let v = self._enrollmentToken {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_CreateEnrollmentResponse, rhs: Sensory_Api_V1_Audio_CreateEnrollmentResponse) -> Bool {
    if lhs.percentComplete != rhs.percentComplete {return false}
    if lhs.audioEnergy != rhs.audioEnergy {return false}
    if lhs.enrollmentID != rhs.enrollmentID {return false}
    if lhs.modelName != rhs.modelName {return false}
    if lhs.modelVersion != rhs.modelVersion {return false}
    if lhs.modelPrompt != rhs.modelPrompt {return false}
    if lhs.percentSegmentComplete != rhs.percentSegmentComplete {return false}
    if lhs._enrollmentToken != rhs._enrollmentToken {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AuthenticateResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AuthenticateResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audioEnergy"),
    2: .same(proto: "success"),
    3: .same(proto: "token"),
    4: .same(proto: "userId"),
    5: .same(proto: "enrollmentId"),
    6: .same(proto: "modelPrompt"),
    7: .same(proto: "percentSegmentComplete"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularFloatField(value: &self.audioEnergy) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.success) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._token) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.userID) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.enrollmentID) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.modelPrompt) }()
      case 7: try { try decoder.decodeSingularInt64Field(value: &self.percentSegmentComplete) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.audioEnergy != 0 {
      try visitor.visitSingularFloatField(value: self.audioEnergy, fieldNumber: 1)
    }
    if self.success != false {
      try visitor.visitSingularBoolField(value: self.success, fieldNumber: 2)
    }
    try { if let v = self._token {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    if !self.userID.isEmpty {
      try visitor.visitSingularStringField(value: self.userID, fieldNumber: 4)
    }
    if !self.enrollmentID.isEmpty {
      try visitor.visitSingularStringField(value: self.enrollmentID, fieldNumber: 5)
    }
    if !self.modelPrompt.isEmpty {
      try visitor.visitSingularStringField(value: self.modelPrompt, fieldNumber: 6)
    }
    if self.percentSegmentComplete != 0 {
      try visitor.visitSingularInt64Field(value: self.percentSegmentComplete, fieldNumber: 7)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_AuthenticateResponse, rhs: Sensory_Api_V1_Audio_AuthenticateResponse) -> Bool {
    if lhs.audioEnergy != rhs.audioEnergy {return false}
    if lhs.success != rhs.success {return false}
    if lhs._token != rhs._token {return false}
    if lhs.userID != rhs.userID {return false}
    if lhs.enrollmentID != rhs.enrollmentID {return false}
    if lhs.modelPrompt != rhs.modelPrompt {return false}
    if lhs.percentSegmentComplete != rhs.percentSegmentComplete {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_ValidateEventResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ValidateEventResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audioEnergy"),
    2: .same(proto: "success"),
    3: .same(proto: "resultId"),
    4: .same(proto: "score"),
    10: .same(proto: "postProcessingAction"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularFloatField(value: &self.audioEnergy) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.success) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.resultID) }()
      case 4: try { try decoder.decodeSingularFloatField(value: &self.score) }()
      case 10: try { try decoder.decodeSingularMessageField(value: &self._postProcessingAction) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.audioEnergy != 0 {
      try visitor.visitSingularFloatField(value: self.audioEnergy, fieldNumber: 1)
    }
    if self.success != false {
      try visitor.visitSingularBoolField(value: self.success, fieldNumber: 2)
    }
    if !self.resultID.isEmpty {
      try visitor.visitSingularStringField(value: self.resultID, fieldNumber: 3)
    }
    if self.score != 0 {
      try visitor.visitSingularFloatField(value: self.score, fieldNumber: 4)
    }
    try { if let v = self._postProcessingAction {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_ValidateEventResponse, rhs: Sensory_Api_V1_Audio_ValidateEventResponse) -> Bool {
    if lhs.audioEnergy != rhs.audioEnergy {return false}
    if lhs.success != rhs.success {return false}
    if lhs.resultID != rhs.resultID {return false}
    if lhs.score != rhs.score {return false}
    if lhs._postProcessingAction != rhs._postProcessingAction {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_ValidateEnrolledEventResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ValidateEnrolledEventResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audioEnergy"),
    2: .same(proto: "success"),
    3: .same(proto: "enrollmentId"),
    4: .same(proto: "userId"),
    5: .same(proto: "modelPrompt"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularFloatField(value: &self.audioEnergy) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.success) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.enrollmentID) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.userID) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.modelPrompt) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.audioEnergy != 0 {
      try visitor.visitSingularFloatField(value: self.audioEnergy, fieldNumber: 1)
    }
    if self.success != false {
      try visitor.visitSingularBoolField(value: self.success, fieldNumber: 2)
    }
    if !self.enrollmentID.isEmpty {
      try visitor.visitSingularStringField(value: self.enrollmentID, fieldNumber: 3)
    }
    if !self.userID.isEmpty {
      try visitor.visitSingularStringField(value: self.userID, fieldNumber: 4)
    }
    if !self.modelPrompt.isEmpty {
      try visitor.visitSingularStringField(value: self.modelPrompt, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_ValidateEnrolledEventResponse, rhs: Sensory_Api_V1_Audio_ValidateEnrolledEventResponse) -> Bool {
    if lhs.audioEnergy != rhs.audioEnergy {return false}
    if lhs.success != rhs.success {return false}
    if lhs.enrollmentID != rhs.enrollmentID {return false}
    if lhs.userID != rhs.userID {return false}
    if lhs.modelPrompt != rhs.modelPrompt {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_TranscribeWord: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TranscribeWord"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "begintimeMs"),
    2: .same(proto: "endtimeMs"),
    3: .same(proto: "confidence"),
    4: .same(proto: "wordState"),
    5: .same(proto: "wordIndex"),
    6: .same(proto: "word"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.begintimeMs) }()
      case 2: try { try decoder.decodeSingularUInt64Field(value: &self.endtimeMs) }()
      case 3: try { try decoder.decodeSingularFloatField(value: &self.confidence) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.wordState) }()
      case 5: try { try decoder.decodeSingularUInt64Field(value: &self.wordIndex) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.word) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.begintimeMs != 0 {
      try visitor.visitSingularUInt64Field(value: self.begintimeMs, fieldNumber: 1)
    }
    if self.endtimeMs != 0 {
      try visitor.visitSingularUInt64Field(value: self.endtimeMs, fieldNumber: 2)
    }
    if self.confidence != 0 {
      try visitor.visitSingularFloatField(value: self.confidence, fieldNumber: 3)
    }
    if self.wordState != .pending {
      try visitor.visitSingularEnumField(value: self.wordState, fieldNumber: 4)
    }
    if self.wordIndex != 0 {
      try visitor.visitSingularUInt64Field(value: self.wordIndex, fieldNumber: 5)
    }
    if !self.word.isEmpty {
      try visitor.visitSingularStringField(value: self.word, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_TranscribeWord, rhs: Sensory_Api_V1_Audio_TranscribeWord) -> Bool {
    if lhs.begintimeMs != rhs.begintimeMs {return false}
    if lhs.endtimeMs != rhs.endtimeMs {return false}
    if lhs.confidence != rhs.confidence {return false}
    if lhs.wordState != rhs.wordState {return false}
    if lhs.wordIndex != rhs.wordIndex {return false}
    if lhs.word != rhs.word {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_TranscribeWordResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TranscribeWordResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "words"),
    2: .same(proto: "firstWordIndex"),
    3: .same(proto: "lastWordIndex"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.words) }()
      case 2: try { try decoder.decodeSingularUInt64Field(value: &self.firstWordIndex) }()
      case 3: try { try decoder.decodeSingularUInt64Field(value: &self.lastWordIndex) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.words.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.words, fieldNumber: 1)
    }
    if self.firstWordIndex != 0 {
      try visitor.visitSingularUInt64Field(value: self.firstWordIndex, fieldNumber: 2)
    }
    if self.lastWordIndex != 0 {
      try visitor.visitSingularUInt64Field(value: self.lastWordIndex, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_TranscribeWordResponse, rhs: Sensory_Api_V1_Audio_TranscribeWordResponse) -> Bool {
    if lhs.words != rhs.words {return false}
    if lhs.firstWordIndex != rhs.firstWordIndex {return false}
    if lhs.lastWordIndex != rhs.lastWordIndex {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_TranscribeResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TranscribeResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audioEnergy"),
    2: .same(proto: "transcript"),
    3: .same(proto: "isPartialResult"),
    4: .same(proto: "wordList"),
    10: .same(proto: "postProcessingAction"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularFloatField(value: &self.audioEnergy) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.transcript) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.isPartialResult) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._wordList) }()
      case 10: try { try decoder.decodeSingularMessageField(value: &self._postProcessingAction) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.audioEnergy != 0 {
      try visitor.visitSingularFloatField(value: self.audioEnergy, fieldNumber: 1)
    }
    if !self.transcript.isEmpty {
      try visitor.visitSingularStringField(value: self.transcript, fieldNumber: 2)
    }
    if self.isPartialResult != false {
      try visitor.visitSingularBoolField(value: self.isPartialResult, fieldNumber: 3)
    }
    try { if let v = self._wordList {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._postProcessingAction {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_TranscribeResponse, rhs: Sensory_Api_V1_Audio_TranscribeResponse) -> Bool {
    if lhs.audioEnergy != rhs.audioEnergy {return false}
    if lhs.transcript != rhs.transcript {return false}
    if lhs.isPartialResult != rhs.isPartialResult {return false}
    if lhs._wordList != rhs._wordList {return false}
    if lhs._postProcessingAction != rhs._postProcessingAction {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_SynthesizeSpeechResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SynthesizeSpeechResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .same(proto: "audioContent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Sensory_Api_V1_Audio_AudioConfig?
        var hadOneofValue = false
        if let current = self.streamingResponse {
          hadOneofValue = true
          if case .config(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingResponse = .config(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingResponse != nil {try decoder.handleConflictingOneOf()}
          self.streamingResponse = .audioContent(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.streamingResponse {
    case .config?: try {
      guard case .config(let v)? = self.streamingResponse else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .audioContent?: try {
      guard case .audioContent(let v)? = self.streamingResponse else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_SynthesizeSpeechResponse, rhs: Sensory_Api_V1_Audio_SynthesizeSpeechResponse) -> Bool {
    if lhs.streamingResponse != rhs.streamingResponse {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_CreateEnrollmentConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateEnrollmentConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audio"),
    2: .same(proto: "userId"),
    3: .same(proto: "deviceId"),
    4: .same(proto: "modelName"),
    5: .same(proto: "description"),
    6: .same(proto: "isLivenessEnabled"),
    7: .same(proto: "enrollmentNumUtterances"),
    8: .same(proto: "enrollmentDuration"),
    9: .same(proto: "referenceId"),
    10: .same(proto: "disableServerEnrollmentTemplateStorage"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._audio) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.userID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.deviceID) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.modelName) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.description_p) }()
      case 6: try { try decoder.decodeSingularBoolField(value: &self.isLivenessEnabled) }()
      case 7: try {
        var v: UInt32?
        try decoder.decodeSingularUInt32Field(value: &v)
        if let v = v {
          if self.enrollLength != nil {try decoder.handleConflictingOneOf()}
          self.enrollLength = .enrollmentNumUtterances(v)
        }
      }()
      case 8: try {
        var v: Float?
        try decoder.decodeSingularFloatField(value: &v)
        if let v = v {
          if self.enrollLength != nil {try decoder.handleConflictingOneOf()}
          self.enrollLength = .enrollmentDuration(v)
        }
      }()
      case 9: try { try decoder.decodeSingularStringField(value: &self.referenceID) }()
      case 10: try { try decoder.decodeSingularBoolField(value: &self.disableServerEnrollmentTemplateStorage) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._audio {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.userID.isEmpty {
      try visitor.visitSingularStringField(value: self.userID, fieldNumber: 2)
    }
    if !self.deviceID.isEmpty {
      try visitor.visitSingularStringField(value: self.deviceID, fieldNumber: 3)
    }
    if !self.modelName.isEmpty {
      try visitor.visitSingularStringField(value: self.modelName, fieldNumber: 4)
    }
    if !self.description_p.isEmpty {
      try visitor.visitSingularStringField(value: self.description_p, fieldNumber: 5)
    }
    if self.isLivenessEnabled != false {
      try visitor.visitSingularBoolField(value: self.isLivenessEnabled, fieldNumber: 6)
    }
    switch self.enrollLength {
    case .enrollmentNumUtterances?: try {
      guard case .enrollmentNumUtterances(let v)? = self.enrollLength else { preconditionFailure() }
      try visitor.visitSingularUInt32Field(value: v, fieldNumber: 7)
    }()
    case .enrollmentDuration?: try {
      guard case .enrollmentDuration(let v)? = self.enrollLength else { preconditionFailure() }
      try visitor.visitSingularFloatField(value: v, fieldNumber: 8)
    }()
    case nil: break
    }
    if !self.referenceID.isEmpty {
      try visitor.visitSingularStringField(value: self.referenceID, fieldNumber: 9)
    }
    if self.disableServerEnrollmentTemplateStorage != false {
      try visitor.visitSingularBoolField(value: self.disableServerEnrollmentTemplateStorage, fieldNumber: 10)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_CreateEnrollmentConfig, rhs: Sensory_Api_V1_Audio_CreateEnrollmentConfig) -> Bool {
    if lhs._audio != rhs._audio {return false}
    if lhs.userID != rhs.userID {return false}
    if lhs.deviceID != rhs.deviceID {return false}
    if lhs.modelName != rhs.modelName {return false}
    if lhs.description_p != rhs.description_p {return false}
    if lhs.isLivenessEnabled != rhs.isLivenessEnabled {return false}
    if lhs.enrollLength != rhs.enrollLength {return false}
    if lhs.referenceID != rhs.referenceID {return false}
    if lhs.disableServerEnrollmentTemplateStorage != rhs.disableServerEnrollmentTemplateStorage {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AuthenticateConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AuthenticateConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audio"),
    2: .same(proto: "enrollmentId"),
    3: .same(proto: "enrollmentGroupId"),
    4: .same(proto: "doIncludeToken"),
    5: .same(proto: "sensitivity"),
    6: .same(proto: "security"),
    7: .same(proto: "isLivenessEnabled"),
    8: .same(proto: "enrollmentToken"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._audio) }()
      case 2: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.authID != nil {try decoder.handleConflictingOneOf()}
          self.authID = .enrollmentID(v)
        }
      }()
      case 3: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.authID != nil {try decoder.handleConflictingOneOf()}
          self.authID = .enrollmentGroupID(v)
        }
      }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.doIncludeToken) }()
      case 5: try { try decoder.decodeSingularEnumField(value: &self.sensitivity) }()
      case 6: try { try decoder.decodeSingularEnumField(value: &self.security) }()
      case 7: try { try decoder.decodeSingularBoolField(value: &self.isLivenessEnabled) }()
      case 8: try { try decoder.decodeSingularBytesField(value: &self.enrollmentToken) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._audio {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    switch self.authID {
    case .enrollmentID?: try {
      guard case .enrollmentID(let v)? = self.authID else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    }()
    case .enrollmentGroupID?: try {
      guard case .enrollmentGroupID(let v)? = self.authID else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 3)
    }()
    case nil: break
    }
    if self.doIncludeToken != false {
      try visitor.visitSingularBoolField(value: self.doIncludeToken, fieldNumber: 4)
    }
    if self.sensitivity != .lowest {
      try visitor.visitSingularEnumField(value: self.sensitivity, fieldNumber: 5)
    }
    if self.security != .high {
      try visitor.visitSingularEnumField(value: self.security, fieldNumber: 6)
    }
    if self.isLivenessEnabled != false {
      try visitor.visitSingularBoolField(value: self.isLivenessEnabled, fieldNumber: 7)
    }
    if !self.enrollmentToken.isEmpty {
      try visitor.visitSingularBytesField(value: self.enrollmentToken, fieldNumber: 8)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_AuthenticateConfig, rhs: Sensory_Api_V1_Audio_AuthenticateConfig) -> Bool {
    if lhs._audio != rhs._audio {return false}
    if lhs.authID != rhs.authID {return false}
    if lhs.doIncludeToken != rhs.doIncludeToken {return false}
    if lhs.sensitivity != rhs.sensitivity {return false}
    if lhs.security != rhs.security {return false}
    if lhs.isLivenessEnabled != rhs.isLivenessEnabled {return false}
    if lhs.enrollmentToken != rhs.enrollmentToken {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AuthenticateConfig.ThresholdSecurity: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "HIGH"),
    1: .same(proto: "LOW"),
  ]
}

extension Sensory_Api_V1_Audio_ValidateEventConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ValidateEventConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audio"),
    2: .same(proto: "modelName"),
    3: .same(proto: "userId"),
    4: .same(proto: "sensitivity"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._audio) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.modelName) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.userID) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.sensitivity) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._audio {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.modelName.isEmpty {
      try visitor.visitSingularStringField(value: self.modelName, fieldNumber: 2)
    }
    if !self.userID.isEmpty {
      try visitor.visitSingularStringField(value: self.userID, fieldNumber: 3)
    }
    if self.sensitivity != .lowest {
      try visitor.visitSingularEnumField(value: self.sensitivity, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_ValidateEventConfig, rhs: Sensory_Api_V1_Audio_ValidateEventConfig) -> Bool {
    if lhs._audio != rhs._audio {return false}
    if lhs.modelName != rhs.modelName {return false}
    if lhs.userID != rhs.userID {return false}
    if lhs.sensitivity != rhs.sensitivity {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_CreateEnrollmentEventConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateEnrollmentEventConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audio"),
    2: .same(proto: "userId"),
    3: .same(proto: "modelName"),
    4: .same(proto: "description"),
    5: .same(proto: "enrollmentNumUtterances"),
    6: .same(proto: "enrollmentDuration"),
    7: .same(proto: "referenceId"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._audio) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.userID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.modelName) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.description_p) }()
      case 5: try {
        var v: UInt32?
        try decoder.decodeSingularUInt32Field(value: &v)
        if let v = v {
          if self.enrollLength != nil {try decoder.handleConflictingOneOf()}
          self.enrollLength = .enrollmentNumUtterances(v)
        }
      }()
      case 6: try {
        var v: Float?
        try decoder.decodeSingularFloatField(value: &v)
        if let v = v {
          if self.enrollLength != nil {try decoder.handleConflictingOneOf()}
          self.enrollLength = .enrollmentDuration(v)
        }
      }()
      case 7: try { try decoder.decodeSingularStringField(value: &self.referenceID) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._audio {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.userID.isEmpty {
      try visitor.visitSingularStringField(value: self.userID, fieldNumber: 2)
    }
    if !self.modelName.isEmpty {
      try visitor.visitSingularStringField(value: self.modelName, fieldNumber: 3)
    }
    if !self.description_p.isEmpty {
      try visitor.visitSingularStringField(value: self.description_p, fieldNumber: 4)
    }
    switch self.enrollLength {
    case .enrollmentNumUtterances?: try {
      guard case .enrollmentNumUtterances(let v)? = self.enrollLength else { preconditionFailure() }
      try visitor.visitSingularUInt32Field(value: v, fieldNumber: 5)
    }()
    case .enrollmentDuration?: try {
      guard case .enrollmentDuration(let v)? = self.enrollLength else { preconditionFailure() }
      try visitor.visitSingularFloatField(value: v, fieldNumber: 6)
    }()
    case nil: break
    }
    if !self.referenceID.isEmpty {
      try visitor.visitSingularStringField(value: self.referenceID, fieldNumber: 7)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_CreateEnrollmentEventConfig, rhs: Sensory_Api_V1_Audio_CreateEnrollmentEventConfig) -> Bool {
    if lhs._audio != rhs._audio {return false}
    if lhs.userID != rhs.userID {return false}
    if lhs.modelName != rhs.modelName {return false}
    if lhs.description_p != rhs.description_p {return false}
    if lhs.enrollLength != rhs.enrollLength {return false}
    if lhs.referenceID != rhs.referenceID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_ValidateEnrolledEventConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ValidateEnrolledEventConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audio"),
    2: .same(proto: "enrollmentId"),
    3: .same(proto: "enrollmentGroupId"),
    4: .same(proto: "sensitivity"),
    5: .same(proto: "enrollmentToken"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._audio) }()
      case 2: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.authID != nil {try decoder.handleConflictingOneOf()}
          self.authID = .enrollmentID(v)
        }
      }()
      case 3: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.authID != nil {try decoder.handleConflictingOneOf()}
          self.authID = .enrollmentGroupID(v)
        }
      }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.sensitivity) }()
      case 5: try { try decoder.decodeSingularBytesField(value: &self.enrollmentToken) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._audio {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    switch self.authID {
    case .enrollmentID?: try {
      guard case .enrollmentID(let v)? = self.authID else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    }()
    case .enrollmentGroupID?: try {
      guard case .enrollmentGroupID(let v)? = self.authID else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 3)
    }()
    case nil: break
    }
    if self.sensitivity != .lowest {
      try visitor.visitSingularEnumField(value: self.sensitivity, fieldNumber: 4)
    }
    if !self.enrollmentToken.isEmpty {
      try visitor.visitSingularBytesField(value: self.enrollmentToken, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_ValidateEnrolledEventConfig, rhs: Sensory_Api_V1_Audio_ValidateEnrolledEventConfig) -> Bool {
    if lhs._audio != rhs._audio {return false}
    if lhs.authID != rhs.authID {return false}
    if lhs.sensitivity != rhs.sensitivity {return false}
    if lhs.enrollmentToken != rhs.enrollmentToken {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_TranscribeConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TranscribeConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audio"),
    2: .same(proto: "modelName"),
    3: .same(proto: "userId"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._audio) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.modelName) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.userID) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._audio {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.modelName.isEmpty {
      try visitor.visitSingularStringField(value: self.modelName, fieldNumber: 2)
    }
    if !self.userID.isEmpty {
      try visitor.visitSingularStringField(value: self.userID, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_TranscribeConfig, rhs: Sensory_Api_V1_Audio_TranscribeConfig) -> Bool {
    if lhs._audio != rhs._audio {return false}
    if lhs.modelName != rhs.modelName {return false}
    if lhs.userID != rhs.userID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AudioConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AudioConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "encoding"),
    2: .same(proto: "sampleRateHertz"),
    3: .same(proto: "audioChannelCount"),
    4: .same(proto: "languageCode"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.encoding) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.sampleRateHertz) }()
      case 3: try { try decoder.decodeSingularInt32Field(value: &self.audioChannelCount) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.languageCode) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.encoding != .linear16 {
      try visitor.visitSingularEnumField(value: self.encoding, fieldNumber: 1)
    }
    if self.sampleRateHertz != 0 {
      try visitor.visitSingularInt32Field(value: self.sampleRateHertz, fieldNumber: 2)
    }
    if self.audioChannelCount != 0 {
      try visitor.visitSingularInt32Field(value: self.audioChannelCount, fieldNumber: 3)
    }
    if !self.languageCode.isEmpty {
      try visitor.visitSingularStringField(value: self.languageCode, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_AudioConfig, rhs: Sensory_Api_V1_Audio_AudioConfig) -> Bool {
    if lhs.encoding != rhs.encoding {return false}
    if lhs.sampleRateHertz != rhs.sampleRateHertz {return false}
    if lhs.audioChannelCount != rhs.audioChannelCount {return false}
    if lhs.languageCode != rhs.languageCode {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AudioConfig.AudioEncoding: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "LINEAR16"),
    1: .same(proto: "FLAC"),
    2: .same(proto: "MULAW"),
  ]
}

extension Sensory_Api_V1_Audio_VoiceSynthesisConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".VoiceSynthesisConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audio"),
    2: .same(proto: "voice"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._audio) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.voice) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._audio {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.voice.isEmpty {
      try visitor.visitSingularStringField(value: self.voice, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_VoiceSynthesisConfig, rhs: Sensory_Api_V1_Audio_VoiceSynthesisConfig) -> Bool {
    if lhs._audio != rhs._audio {return false}
    if lhs.voice != rhs.voice {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
