// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: v1/audio/audio.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

/// sensory.api.audio

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Specifies how sensitive the event threshold of the model should be
public enum Sensory_Api_V1_Audio_ThresholdSensitivity: SwiftProtobuf.Enum {
  public typealias RawValue = Int

  /// Expects about 32 False Accepts per day for Fixed-Trigger models,
  /// and about 10 False Accepts per day for SoundID models
  case lowest // = 0

  /// Expects about 16 False Accepts per day for Fixed-Trigger models,
  /// and about 5 False Accepts per day for SoundID models
  case low // = 1

  /// Expects about 8 False Accepts per day for Fixed-Trigger models,
  /// and about 3 False Accepts per day for SoundID models
  case medium // = 2

  /// Expects about 3 False Accepts per day for Fixed-Trigger models,
  /// and about 2 False Accepts per day for SoundID models
  case high // = 3

  /// Expects about 2 False Accepts per day for Fixed-Trigger models,
  /// and about 1 False Accept per day for SoundID models
  case highest // = 4
  case UNRECOGNIZED(Int)

  public init() {
    self = .lowest
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .lowest
    case 1: self = .low
    case 2: self = .medium
    case 3: self = .high
    case 4: self = .highest
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .lowest: return 0
    case .low: return 1
    case .medium: return 2
    case .high: return 3
    case .highest: return 4
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Sensory_Api_V1_Audio_ThresholdSensitivity: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Sensory_Api_V1_Audio_ThresholdSensitivity] = [
    .lowest,
    .low,
    .medium,
    .high,
    .highest,
  ]
}

#endif  // swift(>=4.2)

/// Request to get a list of the available models
public struct Sensory_Api_V1_Audio_GetModelsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// A model that is available for use
public struct Sensory_Api_V1_Audio_AudioModel {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The name of the model
  public var name: String = String()

  /// Boolean representing if a model can be used in enrollment
  public var isEnrollable: Bool = false

  /// Model type
  public var modelType: Sensory_Api_Common_ModelType = .voiceBiometricTextDependent

  /// Specific phrase used for enrollment (if applicable)
  public var fixedPhrase: String = String()

  /// Required sampling rate for the data
  public var sampleRate: Int32 = 0

  /// List of versions available for this model
  public var versions: [String] = []

  /// The technology backing this model
  public var technology: Sensory_Api_Common_TechnologyType = .tssv

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response containing the models currently available
public struct Sensory_Api_V1_Audio_GetModelsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// List of supported models
  public var models: [Sensory_Api_V1_Audio_AudioModel] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// The top-level message sent by the client for the `CreateEnrollment` method.
/// Multiple `CreateEnrollmentRequest` messages are sent in a stream. The first message
/// must contain a `config` message and must not contain `audioContent`.
/// All subsequent messages must contain `audioContent` and
/// must not contain a `config` message.
public struct Sensory_Api_V1_Audio_CreateEnrollmentRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The streaming request, which is either a config or audio content.
  public var streamingRequest: Sensory_Api_V1_Audio_CreateEnrollmentRequest.OneOf_StreamingRequest? = nil

  /// Provides information that specifies how to process the
  /// request. The first `CreateEnrollmentRequest` message must contain a
  /// `config`  message.
  public var config: Sensory_Api_V1_Audio_CreateEnrollmentConfig {
    get {
      if case .config(let v)? = streamingRequest {return v}
      return Sensory_Api_V1_Audio_CreateEnrollmentConfig()
    }
    set {streamingRequest = .config(newValue)}
  }

  /// The audio data to be recognized. Sequential chunks of audio data are sent
  /// in sequential `CreateEnrollmentRequest` messages. The first
  /// `CreateEnrollmentRequest` message must not contain `audioContent` data
  /// and all subsequent `CreateEnrollmentRequest` messages must contain
  /// `audioContent` data. The audio bytes must be encoded as specified in
  /// `AudioConfig`.
  public var audioContent: Data {
    get {
      if case .audioContent(let v)? = streamingRequest {return v}
      return Data()
    }
    set {streamingRequest = .audioContent(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The streaming request, which is either a config or audio content.
  public enum OneOf_StreamingRequest: Equatable {
    /// Provides information that specifies how to process the
    /// request. The first `CreateEnrollmentRequest` message must contain a
    /// `config`  message.
    case config(Sensory_Api_V1_Audio_CreateEnrollmentConfig)
    /// The audio data to be recognized. Sequential chunks of audio data are sent
    /// in sequential `CreateEnrollmentRequest` messages. The first
    /// `CreateEnrollmentRequest` message must not contain `audioContent` data
    /// and all subsequent `CreateEnrollmentRequest` messages must contain
    /// `audioContent` data. The audio bytes must be encoded as specified in
    /// `AudioConfig`.
    case audioContent(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_CreateEnrollmentRequest.OneOf_StreamingRequest, rhs: Sensory_Api_V1_Audio_CreateEnrollmentRequest.OneOf_StreamingRequest) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.config, .config): return {
        guard case .config(let l) = lhs, case .config(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.audioContent, .audioContent): return {
        guard case .audioContent(let l) = lhs, case .audioContent(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// The top-level message sent by the client for the `Authenticate` method.
/// Multiple `AuthenticateRequest` messages are sent in a stream. The first message
/// must contain a `config` message and must not contain `audioContent`.
/// All subsequent messages must contain `audioContent` and
/// must not contain a `config` message.
public struct Sensory_Api_V1_Audio_AuthenticateRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The streaming request, which is either a config or audio content.
  public var streamingRequest: Sensory_Api_V1_Audio_AuthenticateRequest.OneOf_StreamingRequest? = nil

  /// Provides information that specifies how to process the
  /// request. The first `AuthenticateRequest` message must contain a
  /// `config`  message.
  public var config: Sensory_Api_V1_Audio_AuthenticateConfig {
    get {
      if case .config(let v)? = streamingRequest {return v}
      return Sensory_Api_V1_Audio_AuthenticateConfig()
    }
    set {streamingRequest = .config(newValue)}
  }

  /// The audio data to be recognized. Sequential chunks of audio data are sent
  /// in sequential `AuthenticateRequest` messages. The first
  /// `AuthenticateRequest` message must not contain `audioContent` data
  /// and all subsequent `AuthenticateRequest` messages must contain
  /// `audioContent` data. The audio bytes must be encoded as specified in
  /// `AudioConfig`.
  public var audioContent: Data {
    get {
      if case .audioContent(let v)? = streamingRequest {return v}
      return Data()
    }
    set {streamingRequest = .audioContent(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The streaming request, which is either a config or audio content.
  public enum OneOf_StreamingRequest: Equatable {
    /// Provides information that specifies how to process the
    /// request. The first `AuthenticateRequest` message must contain a
    /// `config`  message.
    case config(Sensory_Api_V1_Audio_AuthenticateConfig)
    /// The audio data to be recognized. Sequential chunks of audio data are sent
    /// in sequential `AuthenticateRequest` messages. The first
    /// `AuthenticateRequest` message must not contain `audioContent` data
    /// and all subsequent `AuthenticateRequest` messages must contain
    /// `audioContent` data. The audio bytes must be encoded as specified in
    /// `AudioConfig`.
    case audioContent(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_AuthenticateRequest.OneOf_StreamingRequest, rhs: Sensory_Api_V1_Audio_AuthenticateRequest.OneOf_StreamingRequest) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.config, .config): return {
        guard case .config(let l) = lhs, case .config(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.audioContent, .audioContent): return {
        guard case .audioContent(let l) = lhs, case .audioContent(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// The top-level message sent by the client for the `ValidateEvent` method.
/// Multiple `ValidateEventRequest` messages are sent in a stream. The first message
/// must contain a `config` message and must not contain `audioContent`.
/// All subsequent messages must contain `audioContent` and
/// must not contain a `config` message.
public struct Sensory_Api_V1_Audio_ValidateEventRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The streaming request, which is either a config or audio content.
  public var streamingRequest: Sensory_Api_V1_Audio_ValidateEventRequest.OneOf_StreamingRequest? = nil

  /// Provides information that specifies how to process the
  /// request. The first `ValidateEventRequest` message must contain a
  /// `config`  message.
  public var config: Sensory_Api_V1_Audio_ValidateEventConfig {
    get {
      if case .config(let v)? = streamingRequest {return v}
      return Sensory_Api_V1_Audio_ValidateEventConfig()
    }
    set {streamingRequest = .config(newValue)}
  }

  /// The audio data to be recognized. Sequential chunks of audio data are sent
  /// in sequential `ValidateEventRequest` messages. The first
  /// `ValidateEventRequest` message must not contain `audioContent` data
  /// and all subsequent `ValidateEventRequest` messages must contain
  /// `audioContent` data. The audio bytes must be encoded as specified in
  /// `AudioConfig`.
  public var audioContent: Data {
    get {
      if case .audioContent(let v)? = streamingRequest {return v}
      return Data()
    }
    set {streamingRequest = .audioContent(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The streaming request, which is either a config or audio content.
  public enum OneOf_StreamingRequest: Equatable {
    /// Provides information that specifies how to process the
    /// request. The first `ValidateEventRequest` message must contain a
    /// `config`  message.
    case config(Sensory_Api_V1_Audio_ValidateEventConfig)
    /// The audio data to be recognized. Sequential chunks of audio data are sent
    /// in sequential `ValidateEventRequest` messages. The first
    /// `ValidateEventRequest` message must not contain `audioContent` data
    /// and all subsequent `ValidateEventRequest` messages must contain
    /// `audioContent` data. The audio bytes must be encoded as specified in
    /// `AudioConfig`.
    case audioContent(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_ValidateEventRequest.OneOf_StreamingRequest, rhs: Sensory_Api_V1_Audio_ValidateEventRequest.OneOf_StreamingRequest) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.config, .config): return {
        guard case .config(let l) = lhs, case .config(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.audioContent, .audioContent): return {
        guard case .audioContent(let l) = lhs, case .audioContent(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// Response to an enrollment request
public struct Sensory_Api_V1_Audio_CreateEnrollmentResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Percent Complete as values between 0 and 100
  public var percentComplete: Int64 = 0

  /// Relative energy of the processed audio as a value between 0 and 1
  public var audioEnergy: Float = 0

  /// If enrollment is successful, this value will be the unique Enrollment ID
  public var enrollmentID: String = String()

  /// Model used for enrollment
  public var modelName: String = String()

  /// Model version used for enrollment
  public var modelVersion: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response to an authentication request
public struct Sensory_Api_V1_Audio_AuthenticateResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Relative energy of the processed audio as a value between 0 and 1
  public var audioEnergy: Float = 0

  /// Success / Failure bit
  public var success: Bool = false

  /// Optional token that will be returned upon a successful authentication if doIncludeToken is set to true in the AuthenticateConfig
  public var token: Sensory_Api_Common_TokenResponse {
    get {return _token ?? Sensory_Api_Common_TokenResponse()}
    set {_token = newValue}
  }
  /// Returns true if `token` has been explicitly set.
  public var hasToken: Bool {return self._token != nil}
  /// Clears the value of `token`. Subsequent reads from it will return its default value.
  public mutating func clearToken() {self._token = nil}

  /// The userID of the authenticated user
  /// Useful when evaluating enrollment groups
  public var userID: String = String()

  /// The enrollmentID of the authenticated user
  /// Useful when evaluating enrollment groups
  public var enrollmentID: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _token: Sensory_Api_Common_TokenResponse? = nil
}

/// Response from a ValidateEventRequest
public struct Sensory_Api_V1_Audio_ValidateEventResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Relative energy of the processed audio as a value between 0 and 1
  public var audioEnergy: Float = 0

  /// Success / Failure bit
  public var success: Bool = false

  /// Indicates the id of the particular sound that was recognized.
  /// Useful for combined models where multiple sound events can be recognized by the same model.
  public var resultID: String = String()

  /// The score of the event between -100 to +100. Smaller values typically indicate an invalid sound while larger values would generally indicate a detected sound.
  public var score: Float = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Provides information for an audio-based enrollment
public struct Sensory_Api_V1_Audio_CreateEnrollmentConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Provides information that specifies how to
  /// process the request.
  public var audio: Sensory_Api_V1_Audio_AudioConfig {
    get {return _audio ?? Sensory_Api_V1_Audio_AudioConfig()}
    set {_audio = newValue}
  }
  /// Returns true if `audio` has been explicitly set.
  public var hasAudio: Bool {return self._audio != nil}
  /// Clears the value of `audio`. Subsequent reads from it will return its default value.
  public mutating func clearAudio() {self._audio = nil}

  /// The unique user Identifer. This value should be a unique email address or username known by the user.
  public var userID: String = String()

  /// The unique device Identifer. This value should be something retrieved by the devie prior to enrollment (like MAC Address)
  /// this value is used to identify a device uniquely across multiple enrollments
  public var deviceID: String = String()

  /// Name of background model to be enrolled in
  /// Background models can be retrieved from the GetModels() gRPC call
  public var modelName: String = String()

  /// Description of the enrollment as entered by the user.
  /// Max length is 1023 characters
  public var description_p: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _audio: Sensory_Api_V1_Audio_AudioConfig? = nil
}

/// Provides information for an audio-based authentication
public struct Sensory_Api_V1_Audio_AuthenticateConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Provides information that specifies how to
  /// process the request.
  public var audio: Sensory_Api_V1_Audio_AudioConfig {
    get {return _audio ?? Sensory_Api_V1_Audio_AudioConfig()}
    set {_audio = newValue}
  }
  /// Returns true if `audio` has been explicitly set.
  public var hasAudio: Bool {return self._audio != nil}
  /// Clears the value of `audio`. Subsequent reads from it will return its default value.
  public mutating func clearAudio() {self._audio = nil}

  /// An identifier for what to authenticate against, either an individual enrollment or a group of enrollments
  public var authID: Sensory_Api_V1_Audio_AuthenticateConfig.OneOf_AuthID? = nil

  /// Unique identifier created at enrollment
  public var enrollmentID: String {
    get {
      if case .enrollmentID(let v)? = authID {return v}
      return String()
    }
    set {authID = .enrollmentID(newValue)}
  }

  /// Unique identifier for an enrollment group
  public var enrollmentGroupID: String {
    get {
      if case .enrollmentGroupID(let v)? = authID {return v}
      return String()
    }
    set {authID = .enrollmentGroupID(newValue)}
  }

  /// A boolean indicating if the response should include an OAuth token for the user associated with the enrollmentId
  /// The OAuth token will only be returned if the authentication is successful.
  /// It's important to note there will be a minor performance hit to authentication, as OAuth token generation is a semi-expensive operation.
  public var doIncludeToken: Bool = false

  /// The model sensitivity
  public var sensitivity: Sensory_Api_V1_Audio_ThresholdSensitivity = .lowest

  /// The model security
  public var security: Sensory_Api_V1_Audio_AuthenticateConfig.ThresholdSecurity = .high

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// An identifier for what to authenticate against, either an individual enrollment or a group of enrollments
  public enum OneOf_AuthID: Equatable {
    /// Unique identifier created at enrollment
    case enrollmentID(String)
    /// Unique identifier for an enrollment group
    case enrollmentGroupID(String)

  #if !swift(>=4.1)
    public static func ==(lhs: Sensory_Api_V1_Audio_AuthenticateConfig.OneOf_AuthID, rhs: Sensory_Api_V1_Audio_AuthenticateConfig.OneOf_AuthID) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.enrollmentID, .enrollmentID): return {
        guard case .enrollmentID(let l) = lhs, case .enrollmentID(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.enrollmentGroupID, .enrollmentGroupID): return {
        guard case .enrollmentGroupID(let l) = lhs, case .enrollmentGroupID(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  /// Specifies the authentication security mode
  public enum ThresholdSecurity: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// Default  Setting.  Targets  low  Imposter  Accept  (IA).  Recommended  when  TSSV  is  used  solely  for
    /// biometric authentication. Generally this mode assumes the user will produce the voice password in
    /// isolation (rather than part of a voice-query) and over short listening windows (e.g., 7 seconds or
    /// less).  This  provides  the  ultimate  rejection  of  imposter  voices  at  the  expense  of  false-rejects,
    /// particularly in high-noise environments 5 dB SNR and below.
    case high // = 0

    /// Targets low False Reject (FR). Recommended to achieve low false reject or for applications where
    /// errors in imposter accept are not considered severe. Provides reduced rejection in extremely noisy
    /// environments. This mode is typically selected when TSSV is used in conjunction with a front-end
    /// fixed-trigger or part of a combined solution for voice-triggering in which the goal may be to gently
    /// reduce  voice-trigger  false  accepts  in  the  presence  of  noise,  or  to  reduce  the  chances  that  non-
    /// enrollees who say the wake word might accidentally cause an always-listening device to false-fire.
    case low // = 1
    case UNRECOGNIZED(Int)

    public init() {
      self = .high
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .high
      case 1: self = .low
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .high: return 0
      case .low: return 1
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}

  fileprivate var _audio: Sensory_Api_V1_Audio_AudioConfig? = nil
}

#if swift(>=4.2)

extension Sensory_Api_V1_Audio_AuthenticateConfig.ThresholdSecurity: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Sensory_Api_V1_Audio_AuthenticateConfig.ThresholdSecurity] = [
    .high,
    .low,
  ]
}

#endif  // swift(>=4.2)

/// Provides information for an audio-based event recognition
public struct Sensory_Api_V1_Audio_ValidateEventConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Provides information that specifies how to
  /// process the request.
  public var audio: Sensory_Api_V1_Audio_AudioConfig {
    get {return _audio ?? Sensory_Api_V1_Audio_AudioConfig()}
    set {_audio = newValue}
  }
  /// Returns true if `audio` has been explicitly set.
  public var hasAudio: Bool {return self._audio != nil}
  /// Clears the value of `audio`. Subsequent reads from it will return its default value.
  public mutating func clearAudio() {self._audio = nil}

  /// Name of model to validate against
  /// Models can be retrieved from the GetModels() gRPC call
  public var modelName: String = String()

  /// The unique user Identifer
  public var userID: String = String()

  /// The model sensitivity
  public var sensitivity: Sensory_Api_V1_Audio_ThresholdSensitivity = .lowest

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _audio: Sensory_Api_V1_Audio_AudioConfig? = nil
}

/// Provides audio configuration information that specifies how to process the request.
public struct Sensory_Api_V1_Audio_AudioConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Encoding of all sent audio data.
  public var encoding: Sensory_Api_V1_Audio_AudioConfig.AudioEncoding = .linear16

  /// Sample rate in Hertz of the audio data sent in all messages. 16000Hz is optimal.
  public var sampleRateHertz: Int32 = 0

  /// The number of channels in the input audio data.
  public var audioChannelCount: Int32 = 0

  /// Required. The language of the supplied audio as a
  /// [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
  /// Example: "en-US".
  public var languageCode: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The encoding of the audio data sent in the request.
  public enum AudioEncoding: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
    case linear16 // = 0

    /// `FLAC` (Free Lossless Audio
    /// Codec) is the recommended encoding because it is
    /// lossless--therefore recognition is not compromised--and
    /// requires only about half the bandwidth of `LINEAR16`.
    case flac // = 1

    /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
    case mulaw // = 2
    case UNRECOGNIZED(Int)

    public init() {
      self = .linear16
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .linear16
      case 1: self = .flac
      case 2: self = .mulaw
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .linear16: return 0
      case .flac: return 1
      case .mulaw: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}
}

#if swift(>=4.2)

extension Sensory_Api_V1_Audio_AudioConfig.AudioEncoding: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Sensory_Api_V1_Audio_AudioConfig.AudioEncoding] = [
    .linear16,
    .flac,
    .mulaw,
  ]
}

#endif  // swift(>=4.2)

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "sensory.api.v1.audio"

extension Sensory_Api_V1_Audio_ThresholdSensitivity: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "LOWEST"),
    1: .same(proto: "LOW"),
    2: .same(proto: "MEDIUM"),
    3: .same(proto: "HIGH"),
    4: .same(proto: "HIGHEST"),
  ]
}

extension Sensory_Api_V1_Audio_GetModelsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GetModelsRequest"
  public static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let _ = try decoder.nextFieldNumber() {
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_GetModelsRequest, rhs: Sensory_Api_V1_Audio_GetModelsRequest) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AudioModel: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AudioModel"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .same(proto: "isEnrollable"),
    3: .same(proto: "modelType"),
    4: .same(proto: "fixedPhrase"),
    5: .same(proto: "sampleRate"),
    6: .same(proto: "versions"),
    7: .same(proto: "technology"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.isEnrollable) }()
      case 3: try { try decoder.decodeSingularEnumField(value: &self.modelType) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.fixedPhrase) }()
      case 5: try { try decoder.decodeSingularInt32Field(value: &self.sampleRate) }()
      case 6: try { try decoder.decodeRepeatedStringField(value: &self.versions) }()
      case 7: try { try decoder.decodeSingularEnumField(value: &self.technology) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if self.isEnrollable != false {
      try visitor.visitSingularBoolField(value: self.isEnrollable, fieldNumber: 2)
    }
    if self.modelType != .voiceBiometricTextDependent {
      try visitor.visitSingularEnumField(value: self.modelType, fieldNumber: 3)
    }
    if !self.fixedPhrase.isEmpty {
      try visitor.visitSingularStringField(value: self.fixedPhrase, fieldNumber: 4)
    }
    if self.sampleRate != 0 {
      try visitor.visitSingularInt32Field(value: self.sampleRate, fieldNumber: 5)
    }
    if !self.versions.isEmpty {
      try visitor.visitRepeatedStringField(value: self.versions, fieldNumber: 6)
    }
    if self.technology != .tssv {
      try visitor.visitSingularEnumField(value: self.technology, fieldNumber: 7)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_AudioModel, rhs: Sensory_Api_V1_Audio_AudioModel) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.isEnrollable != rhs.isEnrollable {return false}
    if lhs.modelType != rhs.modelType {return false}
    if lhs.fixedPhrase != rhs.fixedPhrase {return false}
    if lhs.sampleRate != rhs.sampleRate {return false}
    if lhs.versions != rhs.versions {return false}
    if lhs.technology != rhs.technology {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_GetModelsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GetModelsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "models"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.models) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.models.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.models, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_GetModelsResponse, rhs: Sensory_Api_V1_Audio_GetModelsResponse) -> Bool {
    if lhs.models != rhs.models {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_CreateEnrollmentRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateEnrollmentRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .same(proto: "audioContent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Sensory_Api_V1_Audio_CreateEnrollmentConfig?
        var hadOneofValue = false
        if let current = self.streamingRequest {
          hadOneofValue = true
          if case .config(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .config(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingRequest != nil {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .audioContent(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.streamingRequest {
    case .config?: try {
      guard case .config(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .audioContent?: try {
      guard case .audioContent(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_CreateEnrollmentRequest, rhs: Sensory_Api_V1_Audio_CreateEnrollmentRequest) -> Bool {
    if lhs.streamingRequest != rhs.streamingRequest {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AuthenticateRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AuthenticateRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .same(proto: "audioContent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Sensory_Api_V1_Audio_AuthenticateConfig?
        var hadOneofValue = false
        if let current = self.streamingRequest {
          hadOneofValue = true
          if case .config(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .config(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingRequest != nil {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .audioContent(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.streamingRequest {
    case .config?: try {
      guard case .config(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .audioContent?: try {
      guard case .audioContent(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_AuthenticateRequest, rhs: Sensory_Api_V1_Audio_AuthenticateRequest) -> Bool {
    if lhs.streamingRequest != rhs.streamingRequest {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_ValidateEventRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ValidateEventRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .same(proto: "audioContent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Sensory_Api_V1_Audio_ValidateEventConfig?
        var hadOneofValue = false
        if let current = self.streamingRequest {
          hadOneofValue = true
          if case .config(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .config(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingRequest != nil {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .audioContent(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.streamingRequest {
    case .config?: try {
      guard case .config(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .audioContent?: try {
      guard case .audioContent(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_ValidateEventRequest, rhs: Sensory_Api_V1_Audio_ValidateEventRequest) -> Bool {
    if lhs.streamingRequest != rhs.streamingRequest {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_CreateEnrollmentResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateEnrollmentResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "percentComplete"),
    2: .same(proto: "audioEnergy"),
    3: .same(proto: "enrollmentId"),
    4: .same(proto: "modelName"),
    5: .same(proto: "modelVersion"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.percentComplete) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.audioEnergy) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.enrollmentID) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.modelName) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.modelVersion) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.percentComplete != 0 {
      try visitor.visitSingularInt64Field(value: self.percentComplete, fieldNumber: 1)
    }
    if self.audioEnergy != 0 {
      try visitor.visitSingularFloatField(value: self.audioEnergy, fieldNumber: 2)
    }
    if !self.enrollmentID.isEmpty {
      try visitor.visitSingularStringField(value: self.enrollmentID, fieldNumber: 3)
    }
    if !self.modelName.isEmpty {
      try visitor.visitSingularStringField(value: self.modelName, fieldNumber: 4)
    }
    if !self.modelVersion.isEmpty {
      try visitor.visitSingularStringField(value: self.modelVersion, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_CreateEnrollmentResponse, rhs: Sensory_Api_V1_Audio_CreateEnrollmentResponse) -> Bool {
    if lhs.percentComplete != rhs.percentComplete {return false}
    if lhs.audioEnergy != rhs.audioEnergy {return false}
    if lhs.enrollmentID != rhs.enrollmentID {return false}
    if lhs.modelName != rhs.modelName {return false}
    if lhs.modelVersion != rhs.modelVersion {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AuthenticateResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AuthenticateResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audioEnergy"),
    2: .same(proto: "success"),
    3: .same(proto: "token"),
    4: .same(proto: "userId"),
    5: .same(proto: "enrollmentId"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularFloatField(value: &self.audioEnergy) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.success) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._token) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.userID) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.enrollmentID) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.audioEnergy != 0 {
      try visitor.visitSingularFloatField(value: self.audioEnergy, fieldNumber: 1)
    }
    if self.success != false {
      try visitor.visitSingularBoolField(value: self.success, fieldNumber: 2)
    }
    if let v = self._token {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }
    if !self.userID.isEmpty {
      try visitor.visitSingularStringField(value: self.userID, fieldNumber: 4)
    }
    if !self.enrollmentID.isEmpty {
      try visitor.visitSingularStringField(value: self.enrollmentID, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_AuthenticateResponse, rhs: Sensory_Api_V1_Audio_AuthenticateResponse) -> Bool {
    if lhs.audioEnergy != rhs.audioEnergy {return false}
    if lhs.success != rhs.success {return false}
    if lhs._token != rhs._token {return false}
    if lhs.userID != rhs.userID {return false}
    if lhs.enrollmentID != rhs.enrollmentID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_ValidateEventResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ValidateEventResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audioEnergy"),
    2: .same(proto: "success"),
    3: .same(proto: "resultId"),
    4: .same(proto: "score"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularFloatField(value: &self.audioEnergy) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.success) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.resultID) }()
      case 4: try { try decoder.decodeSingularFloatField(value: &self.score) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.audioEnergy != 0 {
      try visitor.visitSingularFloatField(value: self.audioEnergy, fieldNumber: 1)
    }
    if self.success != false {
      try visitor.visitSingularBoolField(value: self.success, fieldNumber: 2)
    }
    if !self.resultID.isEmpty {
      try visitor.visitSingularStringField(value: self.resultID, fieldNumber: 3)
    }
    if self.score != 0 {
      try visitor.visitSingularFloatField(value: self.score, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_ValidateEventResponse, rhs: Sensory_Api_V1_Audio_ValidateEventResponse) -> Bool {
    if lhs.audioEnergy != rhs.audioEnergy {return false}
    if lhs.success != rhs.success {return false}
    if lhs.resultID != rhs.resultID {return false}
    if lhs.score != rhs.score {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_CreateEnrollmentConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateEnrollmentConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audio"),
    2: .same(proto: "userId"),
    3: .same(proto: "deviceId"),
    4: .same(proto: "modelName"),
    5: .same(proto: "description"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._audio) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.userID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.deviceID) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.modelName) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.description_p) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._audio {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if !self.userID.isEmpty {
      try visitor.visitSingularStringField(value: self.userID, fieldNumber: 2)
    }
    if !self.deviceID.isEmpty {
      try visitor.visitSingularStringField(value: self.deviceID, fieldNumber: 3)
    }
    if !self.modelName.isEmpty {
      try visitor.visitSingularStringField(value: self.modelName, fieldNumber: 4)
    }
    if !self.description_p.isEmpty {
      try visitor.visitSingularStringField(value: self.description_p, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_CreateEnrollmentConfig, rhs: Sensory_Api_V1_Audio_CreateEnrollmentConfig) -> Bool {
    if lhs._audio != rhs._audio {return false}
    if lhs.userID != rhs.userID {return false}
    if lhs.deviceID != rhs.deviceID {return false}
    if lhs.modelName != rhs.modelName {return false}
    if lhs.description_p != rhs.description_p {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AuthenticateConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AuthenticateConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audio"),
    2: .same(proto: "enrollmentId"),
    3: .same(proto: "enrollmentGroupId"),
    4: .same(proto: "doIncludeToken"),
    5: .same(proto: "sensitivity"),
    6: .same(proto: "security"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._audio) }()
      case 2: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.authID != nil {try decoder.handleConflictingOneOf()}
          self.authID = .enrollmentID(v)
        }
      }()
      case 3: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.authID != nil {try decoder.handleConflictingOneOf()}
          self.authID = .enrollmentGroupID(v)
        }
      }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.doIncludeToken) }()
      case 5: try { try decoder.decodeSingularEnumField(value: &self.sensitivity) }()
      case 6: try { try decoder.decodeSingularEnumField(value: &self.security) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._audio {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.authID {
    case .enrollmentID?: try {
      guard case .enrollmentID(let v)? = self.authID else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    }()
    case .enrollmentGroupID?: try {
      guard case .enrollmentGroupID(let v)? = self.authID else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 3)
    }()
    case nil: break
    }
    if self.doIncludeToken != false {
      try visitor.visitSingularBoolField(value: self.doIncludeToken, fieldNumber: 4)
    }
    if self.sensitivity != .lowest {
      try visitor.visitSingularEnumField(value: self.sensitivity, fieldNumber: 5)
    }
    if self.security != .high {
      try visitor.visitSingularEnumField(value: self.security, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_AuthenticateConfig, rhs: Sensory_Api_V1_Audio_AuthenticateConfig) -> Bool {
    if lhs._audio != rhs._audio {return false}
    if lhs.authID != rhs.authID {return false}
    if lhs.doIncludeToken != rhs.doIncludeToken {return false}
    if lhs.sensitivity != rhs.sensitivity {return false}
    if lhs.security != rhs.security {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AuthenticateConfig.ThresholdSecurity: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "HIGH"),
    1: .same(proto: "LOW"),
  ]
}

extension Sensory_Api_V1_Audio_ValidateEventConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ValidateEventConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audio"),
    2: .same(proto: "modelName"),
    3: .same(proto: "userId"),
    4: .same(proto: "sensitivity"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._audio) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.modelName) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.userID) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.sensitivity) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._audio {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if !self.modelName.isEmpty {
      try visitor.visitSingularStringField(value: self.modelName, fieldNumber: 2)
    }
    if !self.userID.isEmpty {
      try visitor.visitSingularStringField(value: self.userID, fieldNumber: 3)
    }
    if self.sensitivity != .lowest {
      try visitor.visitSingularEnumField(value: self.sensitivity, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_ValidateEventConfig, rhs: Sensory_Api_V1_Audio_ValidateEventConfig) -> Bool {
    if lhs._audio != rhs._audio {return false}
    if lhs.modelName != rhs.modelName {return false}
    if lhs.userID != rhs.userID {return false}
    if lhs.sensitivity != rhs.sensitivity {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AudioConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AudioConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "encoding"),
    2: .same(proto: "sampleRateHertz"),
    3: .same(proto: "audioChannelCount"),
    4: .same(proto: "languageCode"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.encoding) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.sampleRateHertz) }()
      case 3: try { try decoder.decodeSingularInt32Field(value: &self.audioChannelCount) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.languageCode) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.encoding != .linear16 {
      try visitor.visitSingularEnumField(value: self.encoding, fieldNumber: 1)
    }
    if self.sampleRateHertz != 0 {
      try visitor.visitSingularInt32Field(value: self.sampleRateHertz, fieldNumber: 2)
    }
    if self.audioChannelCount != 0 {
      try visitor.visitSingularInt32Field(value: self.audioChannelCount, fieldNumber: 3)
    }
    if !self.languageCode.isEmpty {
      try visitor.visitSingularStringField(value: self.languageCode, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Sensory_Api_V1_Audio_AudioConfig, rhs: Sensory_Api_V1_Audio_AudioConfig) -> Bool {
    if lhs.encoding != rhs.encoding {return false}
    if lhs.sampleRateHertz != rhs.sampleRateHertz {return false}
    if lhs.audioChannelCount != rhs.audioChannelCount {return false}
    if lhs.languageCode != rhs.languageCode {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Sensory_Api_V1_Audio_AudioConfig.AudioEncoding: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "LINEAR16"),
    1: .same(proto: "FLAC"),
    2: .same(proto: "MULAW"),
  ]
}
